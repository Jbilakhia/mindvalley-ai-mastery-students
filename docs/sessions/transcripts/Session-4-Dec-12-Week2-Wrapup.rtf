{\rtf1\ansi\ansicpg1252\cocoartf2867
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Meeting Title: Sara & Tyler Speaking: A.I. Mastery \{Q&A + Workshop: Build Automations with AI Modules \'97 Part #2\}\
Date: Dec 12\
Meeting participants: Vykintas Glodenis, Ileana, Conny Fajardo, Vishen Lakhiani, Francesca Facio, Tom Kirby, Sara, Sara\
\
Transcript:\
 \
Me: Trying to find the fucking email. Good. Morning.  \
Them: I'm just combing through the emails. One sec.  \
Me: Good morning, y'all. How's it going?  \
Them: Good morning, tyler. Hello. Hello.  \
Me: Good morning.  \
Them: Asking me about the email that you sent her where they're supposed to be attachments. I was just looking for that email.  \
Me: Everyone.  \
Them: Or was it just stuff that you've updated into the report?  \
Me: I actually just saw that response. So I'll reattach and send those documents. Like, right now. I just goofed and forgot to attach them.  \
Them: Okay? That's great. Thank you. I thought so, but I wasn't sure if they were supposed to go into GitHub or if there was an actual real attachment supposed to be there.  \
Me: It's both like. So I sent them to GitHub also, but I also meant to attach them and I just forgot. So let's see.  \
Them: Yes. Okay? No worries. Well, I sent them to GitHub. Maybe if you would like, you can just clarify everything that you sent me. So, just saying, the document is full with all the. I think it was 84 student questions. That's amazing, by the way. Thank you so much for that.  \
Me: Thank you so much. For that. Yeah, for sure.  \
Them: Yeah, if you like. If you don't address it, I can, of course, address it at the end.  \
Me: Yeah. No. I can do it. Because as long as you all are okay with us continuing to do that, even after today, to support through that, I don't mind watching it. And I feel like we probably need to. Put maybe through next week or something is like, when we'll continue to watch it. Does that sound good? Like Deadline.  \
Them: Yes, that sounds wonderful, if you guys are okay with that. Then of course.  \
Me: Cool. Yeah. I think that would be helpful, especially just, like, considering. Where we are and the state of this. That's what us talents are. I think we were a little bit aggressive in how complicated we made the workflow for just, like, two teaching sessions to try and get everybody up to speed on that. Even with the help of Claude code. So it is good and is doable. But, yeah, just trying to do that and troubleshoot everyone's stuff is just. That's why I think we need to give them the extra support, too.  \
Them: Thank you. And also, it's what I told you in the feedback. I think as long as today, you just draw out the big lines of everything that you've gone over and just, you know, have them, they seem a little bit anxious and overwhelmed. So just reassure them, as you always do, that it's normal. And just reassure them that this is what you've learned so they don't think that they're missing something. Because I think that's a big FOMO thing for them. Like, am I missing something? And just like, this is what you learned so far. These are the documents. Like, this is where you'll find the question. The answer to the questions. This is where you'll find this.  \
Me: Everything. That we're going. Over. This is what you're going to find. Answ. Ered to the question. This is where. Cool.  \
Them: Okay? I think that'll be really helpful. Do they need me to walk through the bigger picture? I think you mentioned in your email when I was just looking now on like the workflows and why, why things are designed that way. I think so. Yeah, I think that'd be good too. And as part of just like this is what we've seen and started to calm anxieties about it. Yeah. Yeah, for sure. I could do that. Yeah, but the feedback has been so amazing. I wish we had longer. Yeah, I wish we had longer. With them, it's like challenging to teach because we don't also don't know what. What they know.  \
Me: Is it? A.  \
Them: You know, like, the levels that they're at as well. But it's. It's all good. We're. We're still going to make sure that they, you know, our support and we have AI mastery next year, so maybe we can take that into account to say, like, okay, we need more time and. I mean, just, like, I know we're over time, but, like, one suggestion I have is, like, as teachers, it's hard to know what the students know.  \
Me: Little. Bit.  \
Them: So even if you group like sections, like Section one is like the Design and mid Journey and all of that, and then like, one section for, like, a group of instructors, it doesn't have to be us on agents, because then, like, you're holding their hand through the process and, you know, end to end what they are like what they know.  \
Me: Different.  \
Them: You know? And. And you can go deeper. I feel like that's what people want. It's like, I won't like to go deeper, but I need the time with the. That's super, super helpful. Yeah. Yeah. We can talk about that more after. Okay. Yeah. If you like. Because we do this for a living as well, so, like, anything, you want to bring Storm with us around our experience and. And, like, things and any ideas. I'd be so happy to do that with you guys so much. Yes, definitely. We can. Maybe. I'LL set up a call. After all, this is.  \
Me: We can. Talk about it. You want? To bring someone.  \
Them: Again so we can talk about next year. Yeah, no worries. Sorry, we're over time. Would you guys like to come with me on the webinar so we can make it even more informal and. Yeah, yeah, yeah.  \
Me: Sure.  \
Them: All right. Thank you. Happy Friday. You're going to start. Now. Oh, I thought it started. So it starts when you hear a call recording, okay? Thank you. Recording in progress. Okay, now I can say happy Friday.  \
Me: There. You go.  \
Them: Ileana and Tyler were like, what is wrong with you? I was just saying, happy Friday, everyone. They're like, there's no one here.  \
Me: Happy Friday, y'all. Happy Friday. She was eager to jump the gun there. That's what it was.  \
Them: Yeah. How is everybody? Sara and tyler. While you're here, I just want to give you a big warm welcome. Today is our last class of this series. We will be missing you, but as you will share with the students, there will be a more support coming from you guys for a little time longer. But I'll let you guys get to it. I just wanted to welcome you into this space and welcome everybody here and get ready for another fabulous class.  \
Me: That. Will be. Support. Coming from. Every. Body here. Sweet. Thank you.  \
Them: Thank you. We're happy to see you guys again. How is everybody doing? It's been such a. Yeah, it's been such a bananas, like, busy time for us, like, the end of the year. Tyler. Tyler and I were like, we're not going to run a cohort in December because we're like, we need time off, and it's been, like, the busiest time. It's almost like if we had a cohort running, it probably would be easier. I don't know. What do you think, Tyler?  \
Me: Yeah. Wow. Yeah, it is what it is. It's all good, though.  \
Them: Yeah.  \
Me: Yeah. Well, happy Friday. So today is office hours session, as you all know. So we're going to do Q and A, but a few, like, quick housekeeping things just to kind of kick off with that. And then we'll get into it here in a second. Is that we have shipped more commits and documentation and even answered another batch of, like, 84 something different student questions. I think yesterday's was when we shipped them like yesterday morning or something like along those lines. So if you all go into the repo or just go to Claude code and do that habit like what we were trying to tell you in I guess on Wednesday session is when it was. To always ask Claude to make sure and check if you have the latest version of the public student repo pulled down to your local version. And that'll help because we're answering the questions in there. We've pushed a ton of different updates for things. You guys have been amazing on helping us flag those and sticking with it. And it's been good. Persistence is everything even you can tell or sr. Like, I've been trying to debug a bunch of this stuff.  \
Them: Yeah.  \
Me: In every waking moment, it feels like. And even I get stuck in some of this stuff and get frustrated from time to time. So just to normalize that. But we're going to go through where we are today. We have everything pushed out into the repo. We're going to talk about how do you pull that down. How do we fix it? No matter. Kind of like where you're stuck at and then even show you a couple of spots that once you get this set up, how do you do observational evals when you're starting to send yourself emails through the pipeliners and Addy B's emails right? Like, how do we go and look at that? Review it, see some spots that people were having it get hung. Spots that I was having to get hung. And what do we do beyond that?  \
Them: Yeah. Yeah.  \
Me: Awesome.  \
Them: And like, wanting to also re emphasize. And we're always like this in class, like when we teach, right? Normalizing that you guys are learning a lot, and you're being stretched in different ways. And you know, you are doing a great job just by even the fact that there's 207 people in here.  \
Me: People.  \
Them: Like, committed to your learning. Because this is all a process, guys. Like, this is a completely different way. Like, I'm sure you're feeling the agenticness in this in terms of how you're working with Claude and things like that, and honestly. Just even that experience of, like, understanding or having an appreciation of, like. Like, the whole agentic experience is a big deal. It's like, a really big deal. So I just wanted to call that out and make sure that you guys are, like, not feeling like, you know, it's totally normal to feel overwhelmed and stuff. But I don't want you to think, like, is this normal that I'm feeling like that I. You know, I'm, like, a bit scattered and stuff. There is a lot that is happening, and I just wanted to make sure that you guys know that. This learning AI thing, especially as you get to this kind of area where it's more agentic and very different. It is as much as a mindset thing as it is a tactical, like, skills thing. Right, so. So you're doing both. You're expanding your abilities in both spaces. And I'm sure that that is, like, feeling, you know, like you're being stretched. So.  \
Me: Yeah. And the other thing I wanted to say, too, is that you all can continue to use that Google form to submit any questions or screenshots like what you've been doing. We'll continue to support, check and respond to that through the end of next week, because as we were talking through this, there's people that have progressed through. There's people that have getting blocked. Like I'm even seeing in here, where there's some people that are still stuck and blocked, others have been able to get across the hurdles that they've run into. So we're really trying to support each of you all and the different things that you might be running into. And we're going to do that through next week as well. Async like what we've been doing here.  \
Them: All done. Yeah.  \
Me: Cool.  \
Them: Yeah. So we're gonna, like, make sure that, you know, the support continues next week. So don't feel like just because, you know, the live experience ends today, that Sara and Tyler are, like, out of the picture.  \
Me: Experience.  \
Them: We want to give you the space to also work through the material and make sure that we can support you through that.  \
Me: To. Also work. So that. We can support you through that. Sweet.  \
Them: Okay? Tyler, do you want to, like, cover maybe? Like, is it useful to cover, like, the updates of what's been, you know, the. The kind of summary of that, and then we can go.  \
Me: Yeah, for sure. So there were a few different things that we needed to tackle for folks like the Stax has been a big blocker for different folks. As you can see in here. Just getting that done from week one, we have shipped multiple different updates to that, depending on the different kinds of issues that people were running. Into.  \
Them: Yeah.  \
Me: So even if it wasn't necessarily an update to the actual code or workflows on some of these things, It was answers to those student questions as well, so that you and your Claude code agent can go and pull that down. Read through it and get that unblocked for you. Basically, we tried to make it so that when we responded to these, if it was applicable, we would have a prompt for you to give to your CLAUDE code to again be able to basically pull this down and do the work for you. Cool.  \
Them: And like, there's a few questions in the chat and I'm looking at the Q and A form as well. Like, while we're on that topic of like, how do I, how do I actually access the new docs and stuff like that, like, like, what is a prompt, I guess, for us to give them to, like, add into cloud code. So that they can start that process.  \
Me: Yeah. So let me get a VS code open here, but with me. All. You get a new window and get. My dummy. Or not dummy, like my simulated student account in here.  \
Them: Yeah. And the first step for you guys is actually to get everything, like, updated, because that will solve a lot of the problems that you've been coming up against. So make sure that the first thing that you do is, like, what we're going to show you now, even maybe do it right now with us.  \
Me: Yeah, for sure. Because even running right up to class, I've been trying to answer more questions and get more commits fixed as we can and are running into them ourselves. For questions you all have sent through, so. Share. All righty. Here we go. All right, so I am in my student version of the repo. Let me just double check. Yes, Student version of repo. And I have my Claude code tab open. Here, let me go ahead and kind of blow this up a little bit so it's easier to read, hopefully. And remember, down here, if you happen to have something over here on the left hand side selected, if you don't want the agent to be able to read that or force it to read it, you can click on this to turn the little slash to the eye so that it's not going to take up that context window. All right, so the first thing is, let's have Claude go in and pull down the latest version of the repo. So. Hey, claude. Good morning. It's Friday, December the twelveth, and we are doing our live session here with the Mindvalley students. This is Tyler, and I'm in my student repo here. I need you to go and look at the public Student repo and see if there have been any comments or things that have been updated on the public GitHub that I do not have pulled back down here into my local version of that. So please go check that and report back what you find. And if you need to pull down new versions. Please go ahead and do that. But do it in a non destructive way so that we're not going to override any work that I've done. Please. All right, so that's going to happen. So when it pulls down the pull anyway, it's not going to overwrite your work. I just put that in there just as mainly as, like, a talking point so that you all would know that as you do these latest grabs, it's not overriding your work. Here locally. It's just going to pull down versions of things here. So we found new commits here. There's like the 84 student question answer commit that I had not pulled down until, like, my version of the student repo yet.  \
Them: All done.  \
Me: And it pulled down some other Claude code prompts here. All right, cool. So your local work and demo tasks have been touched. All right, sweet. Here we go. So from here, what I would do is depending on where you are in the process. I would ask Claude to go and check and see where it is that you've been blocked and help look at the questions and let's see if we can get beyond that. So let's do this.  \
Them: Tyler, as you go on, can you just copy and paste part of the prompt that doesn't include the intro to you and put it in the chat? People are asking.  \
Me: Yeah, for sure. I'll just grab the whole thing and chuck it in there. Let's see. Just for speed. There we go.  \
Them: Yeah.  \
Me: All right, cool. So let's grab that and then coming on down here. All right, Claude, let's pretend like I have been having trouble getting my stacks set up, and I want you to work through that now, here in my local repo to ensure that I have my stacks, like all of the code set up so I can launch it in my local host and it will be connected to. My N8N web hooks, please. So please go and review any of the latest information that you pull down to help get us unblocked and be working on the latest version of all this information. And let's proceed from there, please. Thank you. All right, cool. So let's do that. I'll grab this little prompt right here. There we go. And obviously, I'm going to focus on an area I know that several people have been having trouble with, like, getting past that. So if you're not stuck on this and you're stuck on a different area, the same process is the same. So if you are stuck on, let's say, the W2 workflow and importing that, that's one thing that we can look at fixing. Another thing is I'll show you here in just a moment that we made an update to the workflow in the W1 workflow. So, like the actual email generation workflow in the way that the librarian was working? We had, like, several issues for different reasons. And so to try and have it work in the same way and also simplify it a little bit to get people across the hurdle is, like, not as simplified as in. The functionality of it, but more of the architecture of how we built it out. We did push an update on that, too, so I'll go. Sara, remind me to go back to that here in just a minute when we get done with this Stacks piece. Because that's something we need to go and review here in just a minute. All right. Y'all. So it's checking to make sure I've got node JS installed. It's making sure that I have the N8N workflows that I need to do this. It's got all the webhook workflows in here, and they're running. See here. So now it's going to go get that for mine personally here because it sees I do actually have these and they are set up properly. In my cloud. N8N we're still wrestling. With the NAD support team trying to get this thing figured out with them on there and with our cloud account. So I have this working on Sara and my self hosted NAD account. That's something that's like account specific though it has to do with the webhook addresses for us is what's going on. So here we go. Just like that. All right, so it's launched my Stacks account here. And we are good to go. And I should be able to see my file stores if I've made them at this point.  \
Them: All done.  \
Me: There we go. And then Let me shrink this down just for a second. I'll pop it back up. It's now showing that the browser is up and running. Here's what I need to do. I need to go in and set this webhook. Value that it's telling me. And I need to go get my Gemini API key from the Google AI studio and go and put that into the settings. So let me go ahead and launch this one more time. And mine should already be populated in here. See, it is. Mine is actually going to. This hostinger, webhook, so I'm just going to leave that where it is because this will actually work properly if I do it this way. If I were to paste in this other one, this is my cloud account, webhook, that's not currently working. So if you all are still if you've done this if you're still working with Cloud. Good God. Claude. Code to debug the stacks. And you keep hitting issues with maybe webhook functionality, if that's what it's determining is the problem. That's the problem that we are having with one of our Nadin accounts in the cloud, which is where this webhook is pointing. This other webhook right here that you see on the left hand side is going to a separate innate in account that we also have. It's like our main one. And we host that, so I know the webhook issues aren't an issue in that account, and that's why I'm running off of this one. So if you're having problems with this, please ping us and let us know in the Q and A or in the Google form or both because it help us double check it with you because there's a chance you might need to reach out to the Nana team because you might be having the same blocking issue. From a platform issue that we're still wrestling with as well. So that's something that it's been a point of frustration for us. And I just wanted to say that if that's something you all are running into, It's not that you're doing anything wrong with Claude code that something's wrong here. It's literally like a stack issue. All right, so here's this. I have my API key in here as well. I have my different. Stacks or stores set up within stacks. I have my brand voice, set up my Hattie B's knowledge base. So if I wanted to come in here and. Let's go add in some Hattie B's stuff. Just as an example, I'm going to go click on this and drop a file in. We'll just make this one. Let me find something that's not going to break it. Let's do this one right here. Cool. And upload it. Okay, so here we go. So I have a failed error in the workflow right here. Which is good. I'm glad we got an error so we can actually work through. How would we go about debugging this right here? So what we would do now is I would come down here and grab my entire activity log. Copy that. And I'm going to come back over here into Claude code. Paste this in. And. Then I'm going to come back up here above it. Hey Claude, I want you to look at this activity log and even spin up sub agents to go and review. And don't go into action mode of fixing yet. I want you to go into diagnosis mode here to try and determine why this might have gone wrong. Because I just went to go and upload a file. To the file store, and I got an error, as you can see here. All right. Cool. And Audrey, I definitely see your hand. Sara, while we're doing this, just because it's Q and A day, do you want to bring people up as we're going through this or no?  \
Them: I think I can't. Personal, like, I can't do it. But I think Audrey's question is in relation to the Stacks. Because while you're talking about, I could weed it out. Silk with stacks. I sent a screenshot. It's the sticky one that debugging with the repo and Claude code could not solve. Claude code is saying that there is a problem with the N8N workflow, which I doubted, so did not go ahead with trying to debug the workflow itself.  \
Me: Okay?  \
Them: Yeah, that was the question. Audrey, feel free to, like, say, if that's what you wanted to ask, or whether you have something else related. To the stacks.  \
Me: All. Right. Cool. So we have this running here, another technique that you all can do as well when you're doing this work. Is that when you're trying to work with Claude to try and get something set up or like debug, period, there's a way to kind of. Help diagnose the problem quicker and determine Is this something with the stacks? Is this something with Nan? Is this something with Google Gemini? Something that you can do is Claude can actually ping Google Gemini directly. And that's what we're able to do, so. Okay, I see what happened here. I tried to upload a JSON, and that's why it was an issue. It was the file type that I did. So if I come back over here,  \
Them: All done.  \
Me: It was a poor choice on my part on a file to try and upload. Let's try a different one. Let me just see if I can find. There we go. Here's one right here. Upload this. It's a markdown. Boom, it works. So that was. It was honestly like, that was user error even on my part right there, trying to just like, pick a file to upload. So if you look here, the types of files that Gemini files search supports is PDF, docx, txt, markdown, HTML. And then if you click on this little tool, tip. It even expands even further to show you other files. The file that I chose to upload was like, that's what was throwing an error through there. And so it was actually working. It was just user error, which also happens. But going back to, like, close the loop on that other train of thought. When you're trying to diagnose if it's Is it the stacks like the ui? Is it the webhooks on the back end? Is it Gemini file search? Have I not set something up over there properly? Or my API key is not working properly or whatever it might be? An easy way to do this. Is, you can have Claude do an API call directly to the Gemini file stores to make sure it's working properly. So if I do that right here, and I'm like, Hey Claude, I want to try and I just tried another file to re upload it and I did a markdown file and it worked perfectly. So there was no issue there. But as just a double check and diagnose and help show in the live session here to the students, how would we be able to determine if this is innate in if it's something to do with the stacks or if it's something to do with Gemini. File search. Like ways that we can begin to eliminate things. To try and figure out how to solve it and help you debug faster is to have you do a direct API call to the Gemini file search. So can you do that and use the API key that you already have for that? If you don't have it, let me know and I'll create a new one just for this one off test. So that you can go and see if I have stores set up, if there's information in there. If you're able to actually query the information there, like from Hattie B's and pull something back there to make sure it's working as intended, that'll help us diagnose our system here and see what part do we need to focus on correcting? Because some of the students have been running into different types of errors, and that's what I'm trying to illustrate here. All right, cool. So let's do.  \
Them: Audrey. This what you were wanting to ask question about, since you're on the panel? Hello, sara. Hello, tyler.  \
Me: Hey. Good morning.  \
Them: Thank you for this class. And I know we're very. So you had a lot of different questions concerning with this tag, basically, and I think you're actually doing exactly what I was asking on Monday through the form as well, is kind of showing us how to actually debug life, like, when we're getting onto this problem with the stack where code was not enough in a way to debug the thing and showing us how, you know, that we have to actually get in connection with the N8 and team. So I guess you're doing this now. So I think you're answering my question now. Maybe, hopefully.  \
Me: Hopefully. Yeah. Yeah. I mean. Like, basically, there's three different parts to this particular system, and the way that we have it set up so Gemini file stores, where we're ultimately sending all these files to, and that's where the vector database is going to be. The webhooks are what are the pipes from Nana to get the information? From the stacks, front end to Gemini. And the stacks is like that front end ui. So, like what we've said before, there's more than one way to fix this. There's like Claude can directly just add things on our behalf to the Gemini file store for us. Which is exactly what the Nadin webhooks and the stacks are also helping do. That works long term, but we also wanted to be able to show you all how can you make a real quick front end to be able to upload things to and then have the webhooks work. But. We definitely want to get the webhooks working because if that's a problem, it's going to affect you in other areas. In automations that you try to build out in N8N, not only for class, but just in the future. So you want to get that fixed if that's what we ultimately determine what it is. But it shouldn't also prevent you from being able to continue moving forward in the class, because we can have Claude, Just take our brand voice files, our Hattie B's files, and add them to the Gemini file store on our behalf for us to get that part done. So that's kind of where we're at right here. So in here, it's telling me I'm going to go get a new key just to kind of illustrate how we could test this and determine it. So let's just name this. We'll call this MV2 Friday test. Right here. Create a key. Here we go. So let's copy this. And remember, I'm making an API key here. In google. And we're using this, just temporarily, to give it directly to Claude. Always try and remind folks whenever I do this that I would go and either delete or. Deactivate this key after I do this part. And replace it with a fresh key. All right, Claude, awesome. Here is a fresh test API key for you to go and list the stores, see what documents we have in the Hattie B sort, and also query the knowledge base with some things that the librarian agent might be querying, such as like store hours or whatever it is that you want to come up with. And make sure that it's returning it properly so we can ensure that the Google Gemini part of this is working, and we can check that off the list and the debugging hierarchy here. Also, remind me to come back and delete and replace this key if I need to once we're done with this test, please. Thank you. All right, so I'm going to go ahead and copy this. There we go. And I'm going to paste this in right here. There we go. All right, cool. All right, so this is going to take just a second. Claude is going to go. And there we go. It's already seeing success here. So basically, it's sending these commands straight to Gemini to make sure that, hey, do I have my Gemini stuff at least set up? Because if not, that could be the blocker, and let's just work our way down that list. Here and knock things off to make sure that they're working. So it did that. It found the Gemini file stores, like so. The sections of our knowledge base are in there. It is seeing files that I've added into there, and it's even sending. Questions or queries to that in the same way that the librarian agent would be doing to make sure that when it returns back, it's returning back information that we need and that it's correctly grounded and all of that sort of stuff. So hopefully this debugging makes sense. If it doesn't, like Audrey. Like you too. You can be the un. Sarra can be the voice of everyone. Please stop me and ask me questions. If you all have any.  \
Them: And I think it helps a lot because, yeah, this is what I decided at the end line to try and bypass the problem with NA10. But, yeah. I'm a beginner, and so maybe I'm a good voice for that, for these category of people. But, yeah, it is helpful to see what you're doing right now.  \
Me: To. See what?  \
Them: To bypass, basically.  \
Me: Awesome. Awesome. And what I think it was elena was asking. So do you need a google AI studio API key and a gemini API key? It's one and the same. So I use those words interchangeably because Google's AI models and products that we're using are under the Gemini kind of bucket or brand name. So it's not too different keys. It's the same. I'm sorry for the confusion there. All right. Cool. And here we go. So it's done this. It basically has determined that we have the information, it's returning that we've got. Files in there. Let's see. What did it say up here? Interesting. Find all sores return MTV documents API. Let me check the stacks. Using a different endpoint format, so it's checking here. Okay, this is the thing to call out right here because this right here, if it finds this issue, this is how you know that we need to call tech support at nan the company if it finds an issue. There is a known bug in IT community that if you are getting NADN, webhooks are returning a 404 error message even though the workflows show as active, that is a known NANA issue.  \
Them: All done.  \
Me: And that is something that we can't fix on rn. We have to raise a support ticket with them and have them help us fix that. So it's recognizing because it's trying to ping webhooks in our personal cloud account. And that's the same thing that we're dealing with. It found that issue if it were to ping our hostinger account, our different innate in account. We don't have this issue over there. So it's like it's a very account specific thing, which is hopefully you all aren't running into that because that would be a royal pain in the butt. So it found this. It's saying that all stores are empty. Which is. It's saying it's suspicious. I agree. I don't think it looked in the right spot. So the way that we can help it is if I tell it. In fact, let me go relaunch. The local host because sometimes it helps to show and tell. Here. So I'll just come back up here and find that and click on it so it launches easily. I'm going to choose this knowledge base that I know is in there. And I'm going to go and just take a screenshot right here. Like this. There we go. I'm going to go back to. My Claude. I'm going to hit forward and click attach file and go grab that screenshot. And. Let's see. Which one is. Is it this one? What time is it? No. Here it is. All right, this one. Boom. All right, Claude, it is very puzzling that you weren't able to find the information in the store. I'm not sure if you ping the correct one. In all of my testing and demos, I have multiple different file stores, and I believe you can only search 10 per call, so we might have just gotten unlucky. And you didn't look at the right one there. If you look at this screenshot, you can see that I do have the Hattie B's knowledge base information. It says it's in the stores. So go look there at this particular one and try and do the queries on it. The other thing that you should know, and it's something I'm even talking to in class right now, is that my personal cloud account has that known issue of the webhook returning the 404. That's something that we are actively working with the N8 in support team to fix. And the way that we have personally fixed this is I have another N8N account in Hostinger that we self host that is working perfectly and that's actually what the stacks is connected to now. It's not connected to the N8N webhooks in my cloud account. So I just wanted to give you that point of clarity here as we're working through this test example of how would we debug something and help get this fixed. Just for your knowledge. Too. So look at this and see if you can ping it. And then come back and let me know if you're able to find the information and if the queries are working properly, please. Thank you. All right. Cool. So there we go. Copy that. 's not. Let me paste it now. I'm going to have to do it in, like, multiple pastes, I think. There we go. So copy. No. Claude, you're working too fast. You're working faster than me. There we go. All right, got that next one. And pasting that in. All right, y'all. Right. So we can see, obviously, like, from the screenshot, that we have real documents in there. They're in there. It's going to query the stores here and see what we get. Verifying that the API key works. It knows that it works. It's doing it directly now. All right. Yeah. So this is another thing that if you all happen to run into this Claude fixes itself. We have documentation in here. Like in the commits and in the repo. But this is kind of like someone asked the question the other day of like, do we really need to have it do research or provide it new information if it's trained on the whole body of the Internet? And if you all remember, I was telling you that Google has recently done updates to their APIs and how they do stuff. There's like a Kapora API right here and the File Search Store API, they just change the language and did an update on this. And because Claude's training data has so much information in it about this previous version, that's what it was continually trying to query, instead of the newer version right here, which it recognized. Like it's smart enough it figures it out, but just in case you see this and you're running into it, This is another thing that people have been hitting. So just to even show you what this looks like and how it's problem solving, it's recognizing it and fixing it on its own, I just wanted to call that out and kind of narrate what it's doing as it's going through this. Process. All right. So it's pinging it again. It's using the Flash 2.5 model. Here we go. There we go. Success. All right. So it was able to now ask. And it took me a minute to do it because I had to explain the Claude some stuff about my own account here.  \
Them: All done.  \
Me: But we had success that we know that Gemini API key is working properly. It was even able to send it this question right here of what the store hours from Hattie B's hot chicken, which is similar to a query that our librarian agent would be who's going to be connected to this might be sending and we get the answer back, and it is actually pulling it back and retrieving it properly, and it's answering how we want it to do. So it's fixed it with the Gemini API. It understands that my personal N8N webhooks are giving me this 404 issue. If you're running into that, please let us know so we can help you give you the right prompt so that Claude can even help you send the N8N support ticket in to get that fixed if you're stuck there. And we can help give you the workaround. To keep moving forward while you're waiting on nadm. Because that's what we've had to do. That's where I'm saying we can just have Claude directly push all this stuff for us. To our Gemini file store, and we'll just bypass using the stacks in the webhooks if we want to. So that's kind of the process here of a couple of different things that we've seen students work through. And we were able to kind of show how to debug and test this and what you're running into. So, Audrey, is this similar to what you were running into on your end, just so we can try and help you with yours right now as well.  \
Them: Nice. Yes, thank you. I am not 100% sure it was the 404 error just because I don't have in front of me on my screen right now. I'm looking at your screen, but I'm gonna let you know if it's this error or not, but this is really helpful. Because, yeah, I thought at some point I need to just bypass the stack and go with Gemini only, and that's helpful anyway.  \
Me: Okay? This is. Really helpful. Just. By past. Helpful. Anyway.  \
Them: But basically my error was saying that there was a bug in the workflow in NA10 and offering me to actually change the workflow. Change a node. So that's what happened.  \
Me: It can try and do that sometimes if it's getting a 404 error. If I didn't tell it, I'm trying to save you all some rabbit hole time if you do that because Claude wants to fix this thing. And while it also might recognize that, hey, this could and it even said it on when I've been testing this for students that it recognized that it could be a known issue, but it's still going to see if it could figure out another way around it. Even using the NADM webhooks. I haven't had a success to be able to do it that way of having it try and work around this platform level issue. With the webhooks directly. So if you're seeing that one specifically, and that's what it's determining, like, pause on that. And let us know. And I saw some people in chat are having that. What you want to do is you're going to tell and I'll make sure that we have this. Documented and added into the repo, too, so that it's like an easy walkthrough guide for anyone. But you're going to need to have Claude submit and customer service ticket and an issue on GitHub to NADM to be able to basically follow support ticket. And then you also can go ahead and move past this and say, hey, we're just going to not use the stacks or webhooks for now. Let's go ahead and take my brand voice. That we've gotten out of Echo. And let's take the Hattie B. Stuff, add them to a file store in Gemini. I'll have it reminded again in there to use the file search store, not the corpora name. Like in the API call and push it all up there on our behalf, and that gets it into the right bucket for us. And then we can move on. You don't have to keep spinning your wheels on the Nadine Web hooks because. I can tell you for firsthand, it's taken a minute for them to help us. And probably because I only have on this cloud account. I think we only have like the $50 level plan or something. And we don't have like an enterprise level plan, so they're not good about getting back to us. But we haven't been able to get it solved yet either for our cloud account. So just calling that out and telling you it is a known issue and there is a way to get around it for this particular project also. So hopefully that'll be helpful.  \
Them: Tyler, one question. The beginners around here who do not have a lot of workflows or work on N8 and would it be a solution to delete our account and make a new one?  \
Me: Yeah. I mean, you definitely could try. Yeah, it can work to be able to do that, sign up with a new account. You might even need to do it underneath, like a different email address, potentially. Just so that it doesn't try and go to a previous server that they've spun it up on for your same account. If it's, like, tying it back to that for some reason. That could definitely work though. It's one potential solution to see if you can get it to work. For me, it is an account specific thing, so that's why instead of me spending up a cloud account, already had a different one. So I just moved it over to the self hosted account and it worked immediately. So that was a way for me as I was trying to debug it on rn. Is it the freaking web hooks? Is it the known issue with the cloud account? Is it something else? And as soon as we got it working on our other account, we're like, yeah, it's definitely an account centric problem. So I don't know if it'll work if you just spin up a brand new cloud account. And you're essentially kind of rolling the dice again, and it might work and it might not. So it's worth a shot, though, if you don't have a lot in there. Yeah. Cool. All right. So this is the stacks. Let's go talk about something a little bit different here for just a second. Let me pull this up. Here we go. So this workflow right here, this is the W1 workflow. This is also an update that we pushed now. Because we were having some issues and also because webhooks can become an issue for some people. In the way that this librarian agent was being called from a separate workflow process. We just brought the librarian here instead to effectively do the same thing. We still have agentic rag here in this process. But it's not having to ping to that other workflow that we had. So, just to explain this, even better, Let me save this before I'm back out. There we go. So if we're looking at, we have the librarian tool flow right here. This has caused issues for certain for different people. For a couple of different reasons. So in an effort to try and just. Make. If you can get this working on your end and you don't have any bugs when you're trying to get it up and running, then by all means, like, run with it. If you are having an issue. Are better solution that we've come up with is right here that has been more broadly working for everyone is by bringing the librarian straight to this W1 workflow process. So now, instead of there being that little librarian tool node here, that's different for each and every one of them, We just brought the librarian agent in here. We have connected it with the Gemini. Flash 2.5. This could also be open router and you just choose Gemini Flash 2.5. And we have it pinging, doing effectively the same thing it was doing in that other flow. Just right here. And then we've connected it to all of the agents as a tool. That's what all the little spider legs like going out as it's going out to the different agents in here. So this has been documented and pushed. In one of the commits. So this is an easy way to have your cloud code go, look at this. And make this update to your workflow if you're having issues with this part, because some folks have had issues with the library and workflow. So this will get you up and running. Same thing. We have the exa, which is like the web search MCP is in here and set up. So this is one of the web research scraping tools, deep research tools that we have with our hatch expert that's now in here as well and has been shipped. So if you don't have that added into your workflow yet. We have that debugged in a way, so that it's working for everyone that we've been testing it for now. That was another thing that I wanted to call out that we'd had questions on also, just in case that you're still stuck on that portion. That you should be good to go now. Let's look at something else. While I'm in this flow. Too. Because let's say that. You've got the stack set up, you've done your echo flow, you're on more of the week two part of the homework. And you're getting all this stuff set up, and you're even running executions in here. Of sending test emails to try and get it to work and run through all the way. I've been doing this here, and what we can see is the email comes through. It's passing through all of the different steps in here. Where we have sent them on. We have the Hatch agent. All of them are successfully pinging the librarian to go look at the information and the rag store. The sugar agent is effectively like writing its email. Bishop is QA ing it. Now, this is the tricky part, and this is going to be a little bit different for everyone. When Bishop is doing the quality checks here. It's trying to determine. Is everything answered properly? Is it factually correct? Does this actually sound on brand for Hattie B's? Does this sound on brand for Tyler and his brand voice and how he would write this email? All of these sorts of things. When I was running these tests to try and replicate things that students were saying, my bishop agent was being extra hard on grading the sugar agent and saying it didn't sound authentically enough like me. And that's why I would send it to this QA pass of like, is it ready to go ahead and send it for me to review, or does it send it back to sugar down here to have it try it again? And review it again and it qas it a second time. And I kept having this is a part of what we would call observational evals. I kept having what I would have considered good enough to bring to me and pass these QA gates and bring it back to me in slack so that I could actually review it. I would have let it roll through here, but Bishop was being a very stringent rule follower, and it wouldn't give it a high enough grade. Because it needs to have a confidence score of greater than, like, I even lowered it to 70 on some of these things. To get it to pass through and actually send it on to me in Slack and it would still give it a lower grade. For different reasons. Like it was factually answering correctly. It was generally around something that was subjective. Like, does it sound like me enough or did it sound like too corporate? If you're doing that and you're running into that issue. This is a prompt engineering thing that we would want to fix at this point. The structure of this is working properly and it's actually doing what we want it to do. It's just grading it too hard. And so we have some options. If you're stuck at something like this and this is real world. Prompt engineering stuff like you want to have these quality gates in, and then when you run them, you need to make sure that it's applying it in a way that you would want it to be applied when it's doing self evaluation. So you can have Claude code. Go pull down and look at the latest execution run or sets of execution runs. Workflow runs here in N8N. Look at where it is self reviewing. And calling out, why is it not letting it pass? Basically, because that's what I was doing with Claude. And it was essentially, it set it down at 2 corporate for my casual style, I guess. And that wasn't getting written out in here well enough. So for me, that's signaling, like, one of two things. That either means that I need to go and work to get the SUGAR agent's system prompt and get that dialed in more so that it does authentically sound more like me. And or I need to have Bishop ease up a little bit and not grade it so harshly and be like, hey, I've looked at the email that Sugar wrote. I would have given this a passing score to let it bring it to me in slack. And you're grading it too hard, so we need to have Bishop update its rubric that it's going through to try and grade the output here. The other thing. That's how you would solve it from a prompt engineering point of view. And we can go do that here in just a moment, too, if that would be helpful for folks to see what that looks like. Just let us know in chat. And if prompt Engineering, if you don't want to go through that. Another way that we could fix this structurally is that once it hits this QA gate over here, Instead of it hitting this last QA gate, we could remove this one so that Bishop automatically sends its information and logs it to Sheets and sends it to Hauler and brings it to me. And bypasses this stuff right here. So that I actually get the message and I can lay eyes on it in Slack and say, you know what? I would have approved this anyway. And you can kind of overrule what Bishop would have been saying here. So that's a way you could mechanically fix it also.  \
Them: Yeah. Tyler, while you're there explaining this, could you show people where the prompt engineering would change, like the system instructions, essentially where they can find it? Because there's been a few questions that I've responded around this. But I just want to make sure they can visually see it.  \
Me: Yeah, for sure. So we're going to switch back over to the editor right here. And you're going to click on one of the agents. So let's pick the sugar agent. Right here. It's the same spot for any of them. You click on the name right here. Here in this panel is showing like this is the user prompt. And the user prompt is generally like, we probably aren't going to need to touch that because it's just pulling information forward. The system prompt is right here. This is the system message, so that's what's going in right here. So when you did your updated and personalized version of Sugar, And you had Claude code come and update your workflow to have your personalized sugar in here. This is where it's chucking it in. So if we want to just come and copy this, we can grab the whole system prompt here. And I could come back over here in a new thread in Claude code. So let me just grab this so I can pop open a new claw code here. And if I hit shift enters to give me a little bit of space, and I'll do three dashes. And hit shift. Enter again to go down. This is a little technique. Not just for this, but for any time that you're working with an AI to help you revise prompts, you wrap them in what's called a code block. In markdown. So if you all remember, these three line dashes right here, if we were to do that in something like Google Docs or Notion or Microsoft Word, that's like the raw markdown language to put a line break in. We use that frequently to segment sections off. If we go three backticks or triple backticks. So this is the key in the upper left hand corner of your keyboard. It's one key on my keyboard to the left of the number one. So we're going to go three of those. Hit shift enter twice. And then do three again. So we're making a little container right here. And this is a code block is what this is. In raw markdown. And we're going to paste in our system instructions right here. Okay, so we have the whole thing in here. And what this helps with is it helps prevent confusion on our Claude agent or if we're in ChatGPT or it really doesn't matter. Anytime you want to work with a model in the future and you want to have it help you with prompting, you want to wrap it in something like that. So it understands that it's meant to look at it. And not get confused on who it is anymore and try and turn into sugar instead because or whatever prompt it is that you dropped in here so it signals to it to look at it and not take it on as its Persona basically. Okay, so that's one. And then if we come over here, And I'm going to go shift enter again. I'm going to do three more dashes. Because we're going to do two of these at once. And this is a part of you all might have heard the phrase context engineering. This is a part of bringing all the information that Claude really needs to do this job effectively right here in the prompt. That's what we're going to do. So if we go back over to n8n. And I'm going to grab Bishop's system instructions also. Because this is the problem I'm running into. And I'm going to come back over here and I'm going to paste Bishop system instructions in. And we're going to go all the way back up to the top. Where we left ourselves some space. And this is where I'm going to explain to Claude what I'm saying. What I want it to go think through and look at what the problems are that we're running into. And what it proposes to do for a particular solution here. All right. Hey, Claude, below. I am giving you the system instructions for our Sugar agent and the Bishop agent. What we're running into in our workflow for our W1 workflow. Is that cinema is doing its job effectively. The Hatch agent and the librarian are doing their jobs effectively. When it gets to Sugar. Sugar evidently is riding in a way that Bishop doesn't love. And when it's QA ing it, it's basically failing it on the QA node and forcing it to go down the revision path for Sugar to try it again. Sugar does it. And then Bishop reviews it again. And we're running into a thing where when it's giving it a passing score, it's failing it more frequently than I think it should. When I've looked at some of the outputs, I've thought that the emails that it's writing are decent. But evidently Bishop doesn't think that it sounds authentically enough like me. So I want you to look at both of these system instructions. Go familiarize yourself with the workflow that they are a part of that is in our NAN account and come back. Don't take any actions of fixing things yet. We're still in brainstorming mode here. I want you to help me think through what changes could we make to help us have more success. Because ultimately, even if it's failed twice in the QAs, I'm still okay with it bringing the information to me in Slack so I can review it, because I'm a human in the loop at that point anyway, and I'm going to give it the feedback on how to have it improve the email at that stage to begin with. So hopefully this all makes sense. Feel free to ask me if you have any questions, but go do that work and come back with what you find in your brainstorming session. Thank you. All right. So I will copy. This prompt here really quickly. And before I send it off, because otherwise it's going to be hard for me to grab it once it starts going. And this technique that you're seeing right here is really valuable, like, even beyond this class of how do you go in? You're doing what we call observational evaluations. Which is just a fancy way of saying we've gone through and we've looked to see how this thing is running. What it's doing well, where it's failing, describing it as best as we can and having AI go and help look at this alongside of us. And we're going to come up with some potential fixes here. We're going to decide which ones we actually want to roll with. And then we're going to go fix it and test it again. So that's a part of this whole iterative nature of using AI Right here. And the reason why this is like we said the other day, we talked to our community a lot about this sort of stuff. And describe working with AI as squishy. Right? There's no really firm answers. 80 +B +C or A +B does not always equal C. But this is the process that you all will want to go through to help troubleshoot very subjective things that each of you might see differently. When it's doing things like looking at your brand voice and trying to QA it or actually authentically sound like you, you are the best person to say, oh yeah, that sounds perfectly like I would say that. Or no, I would have said it in this way and come back to a model. The habit help think through this and fix that. Okay, so hopefully this will be enlightening to see. How do we go and troubleshoot this stuff as we encounter these things not only in here, but just in workflows beyond or when you're building agents beyond this? Okay?  \
Them: All done.  \
Me: Sorry. Did you say something? Sorry? Or was that just.  \
Them: Oh, yeah, No, I just wanted to bring your attention to a few things on the screen. But you can finish that first, and then we'll. We'll go to the next question.  \
Me: That. Person. Cool. Gotcha. Okay, so, reviewed the workflow W1 workflow and the agent prompts cinemas. If it's sentiment analysis, basically it's understanding what's going on here, why Bishop might be failing. Too often, the scoring meth is unforgiving. Okay, cool. So Bishop uses weighted rubrics. Safety compliance, brand voice compliance, factual accuracy. Customer impact compliance tone, appropriate compliance, and it's giving it like the weights on here. The problem. Getting A score of 3 acceptable with concerns across a rubric gives us a 60 out of 10, which is an automatic fail. And we need mostly fours and fives to pass. So a single three on a brand voice plus the other ones is gonna is gonna cause us issues. So brand voice compliance is a subjectively high bar like what I was saying. From Bishop's rubric. It's giving us some ideas of how we might want to fix this. Sugar and Bishop may not be perfectly aligned. Sugar has slider defaults and approved phrases it uses. Bishops has its own interpretation of what authentic means. Even though they share similar brand guidelines, it's two different LLM calls. Interpreting warmth and subjectively disagree. So the revision loop doesn't fix subjective gaps like what we're saying here. All right, so brainstorming solutions lower the past threshold is going to be the quickest fix. So changing the past threshold from a 70 down to a 60 to 65 will help get it through the system. So that's one way we could do it. And it's giving us pros and cons here, right? And option B, though, is Add Max attempts Bypass. What you actually want is after two QA failures. Bypass bishop and send to the human with a flag. Something like, if it's gone through twice and it still needs review, that's okay. Send it all to the person anyway and just tell them what's happened. So that's another option. It's actually giving us a couple different here. We can adjust bishop's rubric weights in here. So, like, how it's grading the output for this particular thing? And make bishop progressive. Progressive leniency on revisions. So let's see. It's recommendation to start with Option B, the Max Attempt Bypass, since it matches your stated goal. I'm the human in the loop anyway, and I'd rather see the draft and give feedback myself, other than having Sugar and Bishop spin their wheels. Optionally, we could combine that with option D of progressive leniency by adding a note to Bishop's v.2 prompt. That if the drafted fund is fundamentally good and address the customer's need, be more willing to pass and let the human reviewer make the final adjustments. Okay? I like that idea, actually. All right. I like your idea here, Claude. So what I would want you to do is come back and give me the complete and total system instructions with the option D and option B in place. And then for demo, I'm going to do this manually. I want you to tell me where I need to go and place. These things to ship these updates, please. Thank you.  \
Them: And I also want to, like, mention because a lot of people are like, what is happening right now? This is not part of, like, what you have to do. This is Tyler showing you if you wanted to go because someone a few people were asking before.  \
Me: If you. Want. Someone.  \
Them: If I want to change my agents, how do I go do that? Where do I like access that information? So we're Tyler showed you before was the where you access it, and now he's showing you the how you would make those changes. But that's not core to like. It's just because a few people were like, how do I actually adapt the agents and things like that.  \
Me: Yeah. And the process is similar to for, like, we've been building all this stuff for Hattie B's. Unless we're just really, like, the universal line, I doubt any of y'all work for Hattie B's in here. And you want to make this work for your own business or institution or whatever that might be. It's a similar process we could go through of going and grabbing the system instructions. Explaining to Claude code to go look at this and that we did this in a classroom setting. And that we're now wanting to adjust all of this so that it fits our business or our organization, that we're wanting to build this out. And to brainstorm what are the changes that we need to make so that it fits our use case more closely. So that's why this is, like, a good skill set to learn right here. Not just for troubleshooting in the class workflow, but just how you might go about doing this even after the class, to help create new agent instructions. All right. So once this is done riding, it's updating the system instructions, it's going to do that. And then I could just take these from the agent. So I'm just going to do that here. So let's see here. Which one is this? This is going to be system instructions. Man. It keeps on wanting to jump up on the highlight here. All right, so let's go. All the way. Up here. All right, so here's Bishop. I would just take my Bishop agent. And select all the way down. I think because it's still writing, it's not wanting to let me highlight it easily. There we go.  \
Them: All done.  \
Me: All right, so come all the way down here, make sure you get the whole thing. There we go. I'm going to copy that. I would come back over here into my Bishop agent. I would come right here into this section where the system message lives, and I would just delete this out and paste it back in with the new one. And when I did this copy, I grabbed some things that weren't a part of the instructions as well was like the preamble where it was explaining it. So I'm just going to delete that out until I get to this very opening system or s in the carrots right here, so that you can. Now we have the new updated version. Basically, it's even gone ahead and updated it with a version and the current date and all of the things and the reason for why we have updated it. So we have, like, a little miniature change log in here. And now we can go and test this again right here. Another way that you can do this. Like, while we're on this. This is a really good technique that you all can do. Because we have our. Copy and paste in here. If you click on the nodes and if you're like I would command click on a Mac. I don't remember how you like multi select on a PC like what you have to hold down, but I'm going to click these three nodes of bishop. I'm going to grab the librarian and the nodes that it's connected to, because the bishop's also connected to that. And I'm going to hit command c, or I think it's control c on a. On a PC. And I'm going to come over here into Let me just come over here into a new. Window. Because testing that and rerunning the entire workflow to see, like, how is this working now? It is a bit much sometimes. So instead, I can just go make a new workflow. And just paste this in. And so now I have just the Bishop agent connected to the librarian right here. It's preserved on my settings. And now I can to test this as an actual standalone agent. I can click up here on the plus sign and go trigger manually. I'm sorry, it's not trigger manual. It's like I need to Trigger on chat is what it needs to be, so. Right. Where's it at? Trigger on chat message. Where is it? Not adding it in there, right? Trigger. On chat. Did it drop it in here? Oh, it did. It dropped it over here. I was like, I just didn't see it drop it in. And threw it off screen. There we go. All right, so now I have a chat message in here, so I can just go and talk with this one agent by itself. And give it something to test in here. So this is a really easy way to not have to wait on an entire workflow to run to see if our fix actually stuck. And come in here and test it out really quickly so I can go back over to Claude Code. And tell it that. Hey Claude, I just took my Bishop agent that I've updated and I pulled it in the librarian and all the tools and I put it into a brand new workflow that I'm going to test and QA so I can see how effective our proposed updates on the prompt engineering are actually working. Can you give me a couple of messages that I could put into that agent so we can begin to test it and see if it's going to work. Now, as we do more observational evals, please. Thank you. All right, cool. So. There we go. So good enough. So this one, it's going to write this email for us. And this should, it's saying it should pass with the latency or the leniency, rather. So this is simulating what the sugar agent would be giving to it. You select all this one down, yeah. There we go. I'm going to let it finish for it. Let me select. It's not wanting to let me do it yet. All right, so what it's doing, though, is it's giving me three different type of synthetic email tests that are simulating what the sugar agent would be riding. And it's knowing where we're expecting it to land on the passing. All right, so now it's done. I should be able to highlight it. There we go.  \
Them: All done.  \
Me: All right. So I'm going to highlight all of this message that it created for us. Copy that. Come back over here to this Bishop agent and we can check it in. And this is really useful because it allows us to see in real time what it's doing. So the bishop is pinging the anthropic model here. It logged it to memory. It didn't even feel like it needed to call the librarian. It just went straight to it. Let's see here. I noticed that all the required input fields are empty properly. Let's see what it did. So let's give this back. To claude here. Because it might have. Let's see here. Here's the message that I'm getting back from the Bishop agent for the test. Number one, can you look at this and help me see what we need to update in our message? Because it looks like it was expecting something different in the formatting as well. All right. Oh, I bet I know what it is. It was expecting all the rest of the email too. We just gave it the sugar output and it didn't click. Didn't give us the test from the upstream agents as well. That's what we were missing. So that's what we're adding in now. Because it actually worked like we wanted to. Look, Bishop was. It knows all of the input information it's supposed to be getting. So let me stop this so I can test it again. And it knows that it should be getting all this different detailed info, and that's what I'm going to pass back into it now. So copy. Paste. All right, Claude, I interrupted you. Please pick back up and continue on with what you're doing. Thank you. Cool. Yeah, it's still putting in with the parsed placeholders and not, like, populating it with the data. That's what it's doing, too. Okay? So here we go. Please copy and paste the actual values of the content. There we go. We'll get our two different Claudes on the save agent or same role here in just a minute.  \
Them: All done.  \
Me: Here's the message that we're getting back as well. It looks like we didn't have no. Here we go. That's what it did. Modify. Here. It went ahead and wrote it out all the way. That's what I wanted to do. It just was doing it both ways, with both the structure and without. All right. So evaluate the email. So we just had to get the inputs for what Bishop is expecting to get in alignment with it. And then it should be reporting back. And so here it's still unable to because I'm not getting the input information correct. That's what we need to do, is basically get this info so we can go and test this agent. The main thing I was trying to show you all, though here is how you can take an agent, any of them, out of the. In a line in the actual workflow where it takes forever to actually run through. All of them and then diagnose it as a system. If you're making more granular changes like this to a specific agent, you could temporarily just copy paste them, pull them into a new thread or new workflow and start testing them by themselves, like this, which is what I'm doing here. All right. Hopefully this makes sense. I know we're having to go down multiple different paths and rabbit holes here to try and show you all different techniques and ways to do this stuff and hoping that. Is tracking that you all are keeping up with what? I'm going down multiple different paths. So, Sara, I know you've been wondering.  \
Them: Yeah. I think a useful exercise right now is, like, people, I think we need to set the bigger picture again. Because we've been in the weeds, and I think a little bit people are like, what are we looking at? And where are the workflows and stuff like that. So do you want to just show them, like, workflow one, workflow two, that kind of thing, and where the updated ones are and things like that? Those are the questions that are coming up in the chat that people are wanting to see.  \
Me: Yeah, for sure. So, yes, the workflows.  \
Them: And you guys let me know. Sorry. I'm getting Tyler to show you, like, the different workflows. Let me know if you need me to go over the bigger picture of the workflow, like, of the. The workflow flow. As in, like, you know, where are the agents are and the process and stuff like that. Because I'm just trying to understand where the gaps are so we can help close those gaps for you guys.  \
Me: Are. The. Source. That we can help. Yeah. So they're saying, like, bigger picture, please? Yes, if you want to do that first for a second, I guess.  \
Them: Okay? Okay? Yeah.  \
Me: All right.  \
Them: Sorry, give me one second because I've been busy answering questions and I need to bring up maybe the slide deck. That would be easier.  \
Me: Sweet. I'll swap with it here for a second, then.  \
Them: Okay? Okay? One second, guys.  \
Me: Cool. While you're doing that, I'll swap and let's go ahead. And I'll start troubleshooting in chat over here too, while we're at it.  \
Them: If you can get the Q and A section. I've been trying to mostly answer there as well as in the chat, but the chat moves fast. So if we can get in people to, like, add to the Q and A. Okay, one second, guys. I'm almost there. I don't. I know that you're already, like, dealing with a lot, and I don't want to traumatize you with my. With my desktop screen, so that's what. I'm taking my time on that. I have the messiest desktop screen. It is actually, like, triggering for some people, so I'm trying to get it out the way. Okay, let's, like, level set and really go right back to what we're doing here and where week one was and where week two is and what were the overarching thing that we're trying to. We're building here. So what we're building. Is essentially a customer service department. Our employees are not people. They are AI agents.  \
Me: Custom. Er service. Department.  \
Them: That's essentially what we're doing. The case study that we're using is Hattie B's Hot Chicken. Us, tyler? I don't know. And we wanted to use this case study. To make sure that we can set up the majority of the infrastructure. And the content so that you're not having to deal with that, but you can adapt it to your own use case. We want to make sure that you, like, experience it without having that additional mental load. Of creating your own docs and like, from the whole architecture point of view. So. And I know that there's quite a few people from the chat. Who haven't done week one yet or don't know where to access the information or anything like this. So this would be very confusing for you if you're just joining today. So the best place for you to get started is in Mastery. I believe that there's like the step by step docs and everything around how you get set up. And once you get set up with your tech stack and everything like that, you'll be able to access cloud code. To ask questions and workshop through what you need to build. But essentially what we did in week one. Is we. We're really focused around the setup. You cannot do all of this other stuff that we're showing now without it being set up for you. So make sure you do that first. Session one was around the setup and creating and customizing. Your the first AI employee that fits in that agent department. So. So we customized it with our brand voice so it responds as a customer service representative. And we put some documents in its brain, so to speak, or the knowledge so that it has access to that information. And so we wanted to set that up as the first phase. And then where we are right now is the second phase where we add different employees into that workflow to be able to solve a problem. So think of it as multiple employees. That are in the same workflow. Or department. Think of a department like a work. Workflow, like a department. That work for Hattie B's customer service department. So that's where we, like, ended up. But we had to do the setup and everything first. And so who are the agentic team? And people were asking this in the chat, like, how do I decide what agents I need and what they need, information they need to have access to. And all of the things as you go beyond this, like case study, right? So you, you want to think about, like, if you were setting up the customer service department or a marketing department or whatever you end up doing from learning this framework that we're teaching you.  \
Me: If you. Were.  \
Them: And applying it elsewhere. Say you hired people, like specialists to do specific tasks, right? You would want to know. Like, what does this. What job description do I need to give the specialist, which is the agent, which is what Tyler showed you, is the system instructions that is setting up the personality and the kind of like what this agent is here to do. You want to think about that, and you also want to think about what information. If I were to hire this person, Or bring this person on board. I've given them the job description, right? This is their job. Their job is to read the emotional. Like, when an email comes in like cinnamon, it reads the room in terms of like, is this an angry email? Is it a person asking for help? Is that a person asking for off like? What are your opening hours? All done, right?  \
Me: Looking. At this.  \
Them: What information does this agent need to know?  \
Me: Claude code directly.  \
Them: For them to be able to do the job or to do the have the context to be able to do the job. So exactly like you, if you were going to hire someone, you're going to think through, okay, I need to give them access to our policies, to our whatever. Right. So that's how you think. Through those things, but these are the different agents that we have here.  \
Me: You. Can.  \
Them: And they're all in charge of different specific jobs. The reason why we're giving them different specific jobs and not one agent that does everything is because you're going to get a much better result if you have different specialists with different specializations attached to different knowledge than if you had one agent try to do everything. Kind of like think about you. Like, if you had a big customer service department, do you want one person to do the whole job, or do you want to have a team? Right. So that's why we have the different specialists. Okay? So, and this is all in our, like. Like docs and everything like that. You can even ask podcode. What do. What does each agent do? So I'm not going to go super deep into, like, their actual job descriptions. All done.  \
Me: Spec. Ifically. Attach. To different.  \
Them: That's the idea. And then, like, how it all fits together. So in order for us to have this department that works, we had to set up, like, the workshop, right? Like the space for them to be able to access the information, to be able to do certain tasks, all of that. So that is like the first part of the process, which was the setup. It's essentially setting up. The space, the workshop, the department, the ability for you to interact, all of that kind of thing. Right. So that's on the left side of the screen. Hopefully people can see I'll expand because I know people always say expand. All right, so that is how the, the left side of the screen works with the setup. It's actually giving the all done architecture for all of this to take place. Right. The N8N cloud, the VS code, the cloud code, everything that you set up the stacks with the knowledge base to get the right information. In the right places. That's all a setup. Okay, so what's going to happen in a broad area? We've set everything up. We have our agents. We've already connected the agents for you in the workflows, and we're going to go through the separate workflows. I'm going to talk to them on the screen and then Tyler's going to show you the workflows and point to what each one does. Right, but the. The broader idea is we have a whole agentic team that works for a how to be as our case study. An email comes in. This agentic team. I think there's six agents. It counted the, the filter as a. An agent. But that like this agentic team needs to respond to this email that's come in, right? And we remember we've given them all different tasks. So the email comes in this agentic team. Processes as a team. They're like, oh, this customer's pissed. So we need to, like, make sure that we're reading from certain policy documents or the right agents getting involved and things like that. So they, within the team, within the agentic team, they, they like, work together to get something solved, right? So that. Activity happens, and then you get a response from them like, this is how we would draft the email. And the slack of the role is for. Because remember, we don't. I think I covered this in last session specifically. But we put a human in the loop as part of the process to start with because we want to sure make sure that our agentic team can do the job right.  \
Me: Typ. Es.  \
Them: So part of your approval process. Is like, you're going to read the response that gets given to you. The way that the response ends up is like, hey, this is the, like, draft email. And then you kind of assess. Is this an adequate response? Is it in the right tone? Do we need to change anything up? And then you provide that feedback, and then the team changes things up, and then they draft to send something in Gmail for you. So that's the connection. So that's the broader, like, workflow. Is that there's an the Gmail comes in. There's a step where a generative filter happens. Which, you know, basically goes, is this fan mail? Is this a promo email? Or is an actual customer service? All done. If it is a customer service email, then it passes on like check. Yes, it is a customer service email for Hadabes. It's not a spam mail.  \
Me: Of. Services.  \
Them: It passes it on to Workflow one. Workflow1 is where like, the agents live, so to speak. And like will draft the first, like first go at answering this. That again. Remember I just said like that then like, once they draft that response, it gets sent to you to Slack to like edit, change or whatever. And then that is when Workflow two kind of steps into regenerate the response. And that's the broader picture of how it actually ends up in your Gmail response. So the reason that we have had the two workflows is to enable us to have the human in the loop checkpoint. So hopefully that's given everybody, like, a level set in terms of the bigger picture. Tyler, do you want to now go into, like, showing workflow one, workflow two, that kind of thing?  \
Me: Yeah, absolutely. Give me just one second. I'm answering some of these questions in Q and A too, so let me just paste this last part for Jean before I lose it here. So here's the exact working API format. Here's the exact working API format. Where did that go? Right here. Boom. All right, cool. There we go, y'all. Sorry. And this is the same thing. So I'm trying to answer these questions, like, directly for everyone. The more information you can put in there, like, Gene did that perfectly. She told me exactly what she was running into, what the issues were, and it helped me to quickly diagnose and. Help give. And I've done this for several people in here. And it's also what we're doing in the Google form, sending you the response and then the message to give back to your cloud code agent as well. All right, cool. All right, so let's come back over here and. Share screen again. All right. So, sorry. You wanted to walk through and show basically each of the flows and how they're all connecting together now, correct?  \
Them: Yes, Because I just explained the, like, bird's eye view, and I think will be helpful for them to kind of see. Okay, where do these sit? Show me, like, a little bit more around the logic behind them and why they're there, but from a visual point of view in the workflows.  \
Me: Gotcha. Okay, cool.  \
Them: Yeah.  \
Me: So I have mine in folders. When you import this stuff or Claude and ports and stuff, it's not going to put it in folders for you yet. If you want to create those, you can just come up here in the upper right corner, create a folder, and then it gives you a nice little neat way of being able to put your production version. Of the main email flows in a folder, the knowledge base management and the echo stuff in different subsets in here. It's just easy to find stuff as you get in here and start working through it. So the actual production flow. Now, if you're running off of the latest shipment, we have it down to four workflows now, because we've taken this Librarian tool right here. If you're able to get that working. Some people have been able to get it working fine as it is, and we were able to end up working on our end, but others weren't. So if you're having problem with the librarian, do that git pull and you'll get the newer version. But the way that this process is going to work is it starts out here on the email classification filter. So a new email hits your inbox that you set up and connect here to your Gmail account. And your cloud code is going to get all this set in here and installed, but it's not going to be able to do everything for you. So if you all remember in the previous sessions we've talked about what Claude can do some of these things about, like, 90, 95% of the way for you. And then you have to come in and select the accounts. So once you get this one in here, remember that you need to come in and get it set up with your Gmail account. And if you don't have that connected in your nan yet, you need to just create your new credential right here. And it's just as easy as, like, clicking the sign in with Google button. Choosing the email that you want to use for this workflow of like, where do you want to connect this to? Just for testing. And give it permission. It's like, really, like, click on it. It, launches it. It's really pretty straightforward on that. Let me just do this really quickly. Cool. You're going to give it the permissions. And connection is successful. And now you can close that out and you have it connected here. And I would call this. Just name it up here so it's easy for you to know which one it is. Exc. Ept for the name didn't stick, but that's all right. And you're going to choose the one that you want to work off of, so I won't mind to be this one right here. And that's we're going to select your account, so that sets up your trigger. You're going to do the same thing for your Google Sheets nodes, so you're going to need to click on it and do your authentication there. And that'll get these two, like, working. So if you have any errors on that, but the process is, is like, once you have these things connected, email hits the inbox. It checks to ensure. Hey, is this actually a Hattie B's customer service email? If it is cool, it's going to go ahead and send it through this path. And it's going to send it on to the cinnamon agent in the. The first part of the email pipeline, basically. And if it's not, if it determines that it's spam or an internal email or something that isn't applicable at all, It won't actually send it on. And so I have this connected to my live Tyler and Aibuildlab email account. And I get a ton of email in here, right? Just like you all would if you connected to one of your main accounts. And it's working effectively once we get it set up and connected. Because it checks the email, it comes down here and classifies it. And if we were to click at this, it. It's able to understand and see from this output what, like this is an executive Fireside chat. It has nothing to do with Hattie B. So I need to mark this, label this or classify it. As something different. And it basically, like, kills the workflow, right? So it doesn't send it on into the Hattie B's email workflow chain. Which is exactly what it's designed to do. So if you get this set up and connected and you can start like saying it will check your Gmail account, polling is what it's called. It's a polling trigger, meaning that it goes and checks every 60 seconds for new emails that have come in and it will run them through this in batches. And the ones that pass go from this and your actual test emails that you're sending through for Hattie B's should make it all the way through to the next pipeline. And that gets us through the generative filter part of this. So before I move on, is that clear? Does this make sense or do people have questions on this particular workflow or having blockers here? I want to just probably would be good for us to, like, make sure we can address that before we keep moving forward. Does that look good, Sara? Sorry. I know you can see.  \
Them: Yeah, I think. Just ask. I was just asked. Is it one email to one workflow, or can the workflow work on more than one email address?  \
Me: That. It could, but you would need to set up multiple workflows. Like, I don't. You wouldn't want. I don't even think you really could have, like, multiple different email inboxes as triggers for the same workflow. But if you wanted to do that, because, like, I have, like, tolerant Aibuildlab and I have my, my personal email account, too. And let's say I wanted to. Monitor both of those and then pipe them into this downstream flow. You could do that. You would just want to. The best practice would be to duplicate this. And swap out this inbox right here for the. The second or third or whichever inbox. So that way they're ultimately still all, like, pushing to this, like, W1 pipeline right here. But it's not. It's, like, keeping them separated so it's easy to go in and, like, diagnose. And if you ever have any, like, issues or. I think that would just be best practice. When I was going to make a recommendation, there.  \
Them: Yeah. And people are wanting to know, like, how did you actually, like, do the classification piece? Like, what. How did you tell it? What you mean? Essentially, if you can just go, go there.  \
Me: Yeah. Let's go meta here for a second and zoom out. Like when you're wanting to build any sort of an AI system or workflow. You want to come up with your plan first? Like, what's your overall goal? What's your requirements around that? And this, like, sounds fancy. This could be just a brain dump. It doesn't have to be, like, a really fancy plan. Right? So even if we come over here into. Let's just even do this in Claude desktop, just to kind of illustrate this for a second. Bear. With me one second. I'm gonna get a new chat open here. So here's a new window. All right. Here we go. Hey, Claude, I'm wanting to make a new innate in workflow that's going to help with email classification, and I'm just going to brainstorm and brain dump to you. I want you to ask me any questions that you need me to answer for clarity here. And then ultimately, I want to come up with the game plan or the. The PRD for this build so that I can then go give it to a Claude Code agent or an N agent. To actually build out the entire infrastructure from the PRD and the build prompt. So what I want to do is I want. I have a Gmail inbox. And I want to be able to when new emails hit that, it looks at the type of email that it is and will classify it. And the main one that I'm wanting to be able to pass through here and quote, unquote, pass go are emails that are meant to be customer service emails for Hattie. B's hot chicken. It doesn't have to be the exact word for word. I just. I'm wanting to have a. A model, be able to watch my email. And see. Hey, is this an email that we actually need to respond to? And if so, it'll classify it as such? So that we can pass it on downstream to another workflow that will go about researching and answering this email. So feel free to ask me any questions, and we'll come up with this planning document. And then from there, we'll have the build prompt to go out and actually build this thing, please. Thank you. All right. So I know I just like brain dumped to Claude here, and I'm doing that on purpose. And I'm trying to be as. Not use all the tech bro words in here that. That y'all will learn more. Like, PRD is one of them. I did use that one specifically. So that is an acronym that means Product Requirements Document. And in. In the tech world, it's basically like a specification document or a game plan on what are we building, who is it for? How is it going to work? What are all the parts and pieces of it. And when you tell Claude Prd, it knows what that means. And it's going to try and help, like, figure this out more. So Claude's like, hey, Tyler, this sounds like a solid workflow. Essentially, a smart email triage system that filters for Hattie B's customer service inquiries before handing off to your response agent. Let me ask some clarifying questions for you. So, what types of emails are you receiving that you need to filter out? Okay, Claude, so I'm going to answer your first question here. Pretty much, I would say a lot of my email would be like newsletters, spam. Internal emails, personal emails. I'm actually connecting this to an inbox because this is for a demonstration. So the inbox I'm connecting this to is my tyler@aibuild lab gmail account, which obviously isn't Haddb's, but we're doing this to build out a workflow and test it as a Hattie B's customer service email response flow. And this is going to be our quote, unquote, generative filter. That helps weed out any other emails so that my normal emails that come through won't hit the Hattie B's workflow. Okay, so that's explaining that part. The next part, and this is a good process, too. Is like have the model ask you questions. And it'll ask you things that you might not even thought about yet. Which is great, because that gets us more clarity. For our plan. And once we have our plan together, then we're able to go and give this to either Claude Code. Or the NAN agent, and it will just go, like, build the thing for us from scratch. That's literally. This is the process I went through to build this thing from zero for the class is doing this exact thing I'm doing right now.  \
Them: Tyler, the gonna get blown up. Can you just put that prompt, the original prompt in the chat?  \
Me: Yes, ma'am. Yeah, I can do you all one even better. What I will do is I will make this whole chat like public from Claude and just share it so people can see the whole back and forth in here. Yeah, so I'll do that here in just a second. Okay, so the other question I asked was Hattie B's email specifically, are these coming from a dedicated support address or general email? For this exercise that we're doing here. To answer your second question, I've been sending the emails from one of my personal Gmail accounts. So they're just, like, coming in as Hattie B's type questions. So it's not coming from, like, Yelp or Google reviews or actual customers. Is it all going to be synthetic emails? But we need the model to be smart enough to recognize. Oh, hey, this is a Hattie B's email. I need to tag it as such so it gets to pass. Go, please. Thank you. All right, so there's another one. Number three. So there'd be multiple classification categories. Yes. Think through the different kinds of emails that I'm most likely to get and then have some sort of a catch all bucket in there as well. So we have different kinds of categorization. So the model has options to choose from. So it's recognizing that it's not trying to fit everything into a Hattie B's category, please. Thank you. So you can think about internal emails, newsletters. Spam personal emails that I might have coming into my inbox. All of those we do not want to pass go. Only emails that we're sending through that are Hattie B. Specific are the ones that get to come through. All right, cool. What's your preferred trigger cadence? I want this to fire in real time for every new email that comes through, please. When an email comes through that doesn't qualify. I just wanted to kill the flow and stop there. So it only uses a minimal amount of AI tokens to classify it and then it's done. If it's not Hattie B's, it stops the workflow and it doesn't need to proceed on. Let's see. For the emails that do qualify, how do you want to hand off to a downstream workflow? We are going to have a separate workflow set up that we are going to build later that this will then send the original. Like, if it does pass go, it'll send all of the information about that email. On downstream so that it can think about reason, plan, execute, and write the response back to it. And know exactly which email it's going back to reply to and all of that sort of stuff. So we need to make sure that we carry that information forward, please. Thank you. All right. Are there rate limiting concerns? No, I don't think we're going to run into any rate, limiting issues. And the response email isn't done yet. But if you want to go ahead and make the output schema for this workflow, we will use this for now and build the next workflow to match this or make an update at that point if we need to. All right. So there's me answering all the questions. Now, I want you to think through this and then come back and give me the full PRD and a prompt. That I can go and give to the Nan Builder agent. In their cloud account. And it go build this thing for me completely from scratch. And I want to make sure that the model that I use, is it going to cost me a ton of money to be able to do this classification task every single time. Thank you. Okay? So there is kind of the brain dump process, and depending how complicated the thing is that you're wanting to build, right. Like, if there's more parts and pieces to it, like there are to this system, it's good to just kind of come up with your big overall plan. And then come back and work through the parts and pieces of it that you need to build out, like the individual modules, like this. And have all the documentation or have Claude help you write or chat gbt, whichever you prefer, help write all of this documentation for you, and then even a build prompt to then go out and build the thing. This is the whole idea of Agent Orchestrator that Sara and I have been talking a lot about, and in fact if you want to see this in practice, even more in a completely different set and setting. We did a free lightning lesson yesterday, actually, on the maven platform, demonstrating this exact process where we made a veterinarian agent that helps an actual vet that has come through our class. To take in new patient information and write the documents for them that they need to have happen. And so we just basically did this process of he and I live in class one day, just talked about, hey, what do you need this thing to do? What are your requirements? How do you do this thing now? And we gave that to the model. The model did this whole PRD document for us and a prompt. And then we gave it. We not only made the agent, we made the agent and then we went and gave it to the N8N and in Cassidy. We did it in both yesterday in the demo, and it built the thing for us, like, super fast. And it worked perfectly. So if you all are interested in that, we can grab maybe the URL and share that. It's like about an hour long video or so that walks through exactly what I'm doing now. That shows you know what this looks like in the real world. That would probably be super valuable for you all. All right, so here we go. So it did our prd here. And I'm going to copy our prompt that it wrote for us. And I'm going to come down here because it wrote in and out of it. Okay? And then I'm going to even copy all the way down here. Boom. Now, let's come back over into Nana. And I'm even going to go into a new email so you all can see. Even since we've been talking, I've had a couple of new emails hit my inbox. And they've successfully run like it skipped it because it's filtered it out at one of the pre filter or the classification filter right here. So that's super. It's working as it should. It's really like a valuable workflow there. All right, cool. So let's come back over here. To. Let's. Just do this. Let's go. New tab. Have all the tabs open right now. I feel like my browser. Like, this is why I love arc, because I can just make it go away. And my Monica's closet. Could just, like, disappear for a second. All right. So I have my prompt copied from what I got from our CLAUDE from our brain dump over there. And y'all have seen how we do this process with CLAUDE code. So if we wanted to, we could just go give that PRD and the prompt to CLAUDE code and have it go build the thing that's like, one way we could do it just for the sake of variety. We could also come in here into NAN and they have this, like, nana AI right here, and you get X number of credits a month. If we were to paste this in. And we even have a limit right here, so let's see where it cuts off. Cool. Let me go. Actually, tell that to Claude. So we have a 5,000 character limit. We'll troubleshoot this in real time, so, boom. Hey, Claude. So I went and copied and paste this into the NAN agent and it has a 5000 character limit. I've pasted back in exactly where it cut it off at. So look at this and then give me the prompt to give back to the agent that will fit within the required characters that it allows. Please. Thank you. All right. The bonus of, like, there's, like, trade offs with everything here. If you were to take this prompt that it makes and go put that back into the NAN agent, like, you only get so many credits here with your account each month and that's it. And so. You can kind of circumnavigate that some too. If you already have Claude code or codex, like what we've been using, and have them go build it on your behalf. And you're saving your credits over here. Or you can kind of go back and forth and use both, if you have both. But I just wanted to show look how you could do this in a couple of different ways. All right, so there's that. Let's copy this new prompt that it made us. Let's paste this in over here. And let's send this through. And so while this is kind of baking in the oven, We'll come back and look at it here in just a second because it'll take it just a minute to build. So. Okay, well, that's running. I'm going to come back over here, Sara, because I know we kind of like we went to go show. How do you do this thing? Right? Do we have any other questions about this classification filter before we kind of.  \
Them: Okay? I have one. Yeah, I have one question, I think from someone. But you guys, what Tyler showed you there was, like, how you would go do it. Like, we'll stay on track on, like, the different workflows. Cause people were just like, where are we now with the different workflows and stuff? So the one question that did come up was, like, how do we know that the generative filter didn't, like, do a mistake and there's a customer service email in like, that that was incorrectly classified, essentially?  \
Me: Yeah, great question.  \
Them: I hope I got that right.  \
Me: Yeah. So that's going to be through eval, too. So, like, the way that you're going to know that is if you look at your executions in here, you can see if it's running or if it's. If you have any errors and it fails out, because it could be like some sort. Of an error. Like here we have one. At some point that it looks like it tried to send it to the cinnamon agent over in this other workflow and it failed. For some reason, we had to figure out why. Now, if it's misclassifying things, that's a different thing, different place. I would check that out. That would be over here in the. This is where it's sending to. Is this workflow one? Which is the big workflow that has all the different agents in it. If you look at the executions of this. This flow only executes if the the previous one sends stuff to it. Okay, so, like, if it's misclassified an email and send it through in here. We're going to know and it's going to run it through this flow and it's going to. It's going to send you a message in slack. But in here. Like, honestly, like, the agents are going to recognize in this flow. It's not going to make it through here. They're going to recognize, oh, hey, something slipped through the gaps. This isn't actually an email for Hattie B's that we should even be responding to. And. And they'll, like, say, that. And so this will generally, like, successfully run and halt or error out over here. So we have that filter in place upstream. The agents here will also, like, look through and are aware enough to know, like, the types of emails they should be expecting. And absolutely worst case scenario if something made it through. Let. Let's say I got like a Hattie B's email or something from them and for some reason it like slipped through this filter. It's ultimately still coming to us in the at the Human and the Loop checkpoint in Slack. So that we're going to be able to see it too. That's why we put things like that in place, so that there's like a stop gap and it doesn't just go in autoresponder, something that it's not supposed to. And if we find at that stage, like either here in the execution runs, where we see an email made it through the cracks and hit this flow that shouldn't have, well, then that tells us we can use that, like take that run. Go to Claude Code and say, hey, if you go look at the execution that ran on December 12th at like 115, you can see that the email that came through is not actually a Hattie B's email. So we need to go upstream. And diagnose how it made it to here so that we can correct that so it doesn't happen in the future. So, literally, just like, explain the Claude what happened in plain language. And it will help you go troubleshoot, resolve, and fix that. So that we. We patch it and it won't happen again, basically. So hopefully that that helps explain. So what happens now, Sara? Do we still have questions or we want to keep moving.  \
Them: Yeah. Oh, yeah, no, sorry. I was just gonna make a mental context switch. So what we just went through right now is right at the beginning of the workflow. Customer service email comes in, the first thing that happens is, like, the determination. Is this a customer service email, or is it spam, or is it whatever? So that workflow that you just saw, now, before we move on, that is what that workflow does first. It just filters and goes. Does it. Does it need to go to the agent department or not? Right? And now we're gonna go. We're gonna assume that it was a pass, that it is a customer service workflow. So what you're about to see now is the next workflow, which is where the agents kind of, like, work on the response.  \
Me: That's right. So now, if it passes go on that first filter and it's meant to come to the department, that's where it enters here. I have currently because I've still been. Testing and troubleshooting some of the student questions that have come through. I have this Gmail node toggled off. And I have the memory toggled off temporarily, like, it's just deactivated. But what's supposed to happen when this is set up is that it will label the email at this point that, hey, this is, like, in the pipeline. So it actually goes and adds a label to it in my Gmail account. So that if I ever need, if it blew up in here, I can easily go and look in my Gmail account and see, well, what email was that? Even so I could go and, like, find it properly. Select. It's applying the tag. It goes to our cinnamon agent right here. Cinnamon is being powered by haiku. Well, actually, Sonic 4.5 is what I switched it back to. It could be sonnet or haiku 4.5 or honestly. Even like flash 2.5 or one of the chat GPT models. Model choice is a bit of a Chevy vs. Ford decision at some of these stages. So, like, there's not necessarily a wrong answer for some of these things, other than. You don't need to be using, like, a crazy expensive model for some of these tasks in here. It's just, like, not needed. So Cinemon is doing the sentiment analysis. It's also connected as a tool down here to our librarian, just like our other agents are. So we see these little lines that are going and connecting to these other agents, because that's because all of them have a pipeline. And like to be able to pick up the phone and call the librarian. Which is where our information is stored in Gemini that we put in there from the stacks. So our brand voice analyses are in there. Are knowledge based information about Heidi B's is in there. And like anything else that we would want to put into that knowledge based system. Lives with the librarian so cinema can go and ping it there. Same thing with Hatch. Once it's done its work, it hands it over to the Hatch, which is our expert level agent. It's doing its role. It's also connected to the librarian. In addition to that, Hatch is connected to Internet research right here. So it can go and double check, like, hey, someone asked when's the midtown location going to be open? And the email just came through today, and they're like, I'm going to be coming into Nashville next week. So Hatch is smart enough to look at the library. Go pull that information back and verify it. And then it might also recognize. Oh, hey, I need to check on holiday hours. And if it's going to do that, the library might not be up to date with that, right? So it's going to go and look and use the MCP tool or the web research tool right here from exa to go and find that out. And that's what's happening here. So it's using both of these tools. It's then taking its information and passing that forward to Sugar. Sugar is our email copywriting agent. It's also connected to the librarian so it can understand how would Hattie be the company want to write this and answer from that? And how would Tyler have written this email? Or how would you have written this email? Because your brand voice is in there and we've personalized this agent so that it knows to write like us working as a team member for Hattie B's. Sending this email. So that's what's happening here. From here. It's tagging. They're updating the tag basically, in Gmail and saying, like, it's made it past the sugar stage. And then it goes to Bishop. Bishop is a QA agent that's reviewing the work. This is the one that was saying, is this actually the correct hours for Midtown? I can go and double check. Is this actually sound like Tyler? I can go and double check. Is there any safety issues with this message that it's responded that we shouldn't respond to? It's going to check all that kind of stuff, and then it determines does it pass go or not by putting out a numerical score on that, and that numerical score gets filtered at this little step right here. So this is the output it's going to give. And it's saying, is that greater than 70? So this is like when we were talking earlier on this call and saying that Bishop was being a really hard critic and a strict rule follower on this. If it doesn't pass it high enough, this is like a fork in the road. If it passes here and they get a 70 on it. It goes up on this path right here. If it fails and it scores less than a 70, it comes down here. And it gives it back to sugar. Sugar again has all the previous information. Plus the feedback from Bishop, and it gets to try it again, and so that's what it's doing here. And from here, it updates the tag. It hands it back over to the Bishop agent for review again. And then from here, if it passes go, there's another. Like, this is called, like, a switch, where it decides if it's going to go, which path it's going to go. I kind of think of this as, like, if you're looking down on a railroad and you have to, like, you know, move. That thing to change which way the train is going to go. That's kind of what we're looking at here is this signpost of, like, which way are we sending this thing? So if it passes. It's going to come and log it into Google sheets so we have long term memory of what's taking place. And we have our hauler agent that looks at that and sends it to us in slack for human and loop review. So that's a lot of what's happening in here. And, and effectively all this happens, you know, completely autonomously. And all we see from an experience from our end is that an email hits our Slack inbox and we just have to read it and respond to it, say, yep, that's perfect. Please go ahead and and send it on to the customer. No. I need you to make this revision. You miss this, and I want to make sure we emphasize this part, or I would have said this differently, whatever that might be that we give just as feedback in Slack. And when that happens. We go on to another, like the next workflow in line. So.  \
Them: Wait, before. Before we move to that one. Tyler, a few people are saying that your workflow looks different to theirs.  \
Me: Yeah. I would go and do the latest get pull. Because even this flow that I have pulled up here might be, like, slightly different than the one that's there, because this is the one I've been using to, like, troubleshoot students work also. So there's like, I have some things, like, toggled off and have some nodes, like, moved around because I'm trying to debug things for them too. But like, this is essentially like the, the main kind of workflow. And if you haven't done a git pull recently, you definitely want to do that, because the librarian here is one of the newer updates that might unblock a lot of folks from things that they were running into and the questions that we had answered.  \
Them: Isabel and Simpatico design. When was the last time you did the poll? Because they're saying it's not there.  \
Me: Okay?  \
Them: Five minutes ago.  \
Me: Five minutes ago. So in the pulling of sauce, saying it, okay. Let me. I'll have to go look after class because this should all be shipped up there right now, so I'll go double check and make sure it is. But yeah, I've been shipping commits, so let me make sure it actually shipped this with the latest version. Too, so. Yeah, like I said, definitely can make it the habit to keep doing the poll. And then talking to your clog code agent to look at the latest versions to see if it if the corrections have been shipped. That gets you over the hump because we're continually shipping. I've shipped some this morning and shipped several yesterday too, so I'll go check and see if one of them didn't get pushed all the way or something and see what's going on with that. Okay? Cool. Do we have any other questions on this flow before we carry it forward to the next workflow? Sara?  \
Them: Yeah, I think. I think just everybody's saying the same similar thing around the access to it, essentially.  \
Me: Okay?  \
Them: Yeah.  \
Me: All. Right.  \
Them: Okay?  \
Me: Let. Me come back out here. I'll go check that once we're done with class and make sure that everything has been pushed and that it didn't just get committed and not pushed. So that we're. We're golden here. All right, so now what we have is we have the. The filter that has happened. If it passes Go, it goes into our first workflow for email processing. From here. Once we answer this, it hits this flow. This is like our. Our kind of router agent, if you want to think of it like that. And this is looking into our Slack channel that we have set up. And so you're this again. This is something that. That Claude code should walk you through. It can get all of this stuff imported and in place. And then you have to come in and, like, set up your credentials for your Slack account. And then also assign your credentials for your Google sheets and your Gmail accounts over here also. But what how this is working is you respond to the message from. From Holler that messages you in Slack. And it comes through here, and it determines with this classifier. Did Tyler say or. Or did you say that? Yep. This looks good. Go ahead and send the email. And if it does, this is like another one of those, like, railroad forks in the road. It'll send it down one of these paths. If we've said that we are revising it, it's going to go through a revision path. If it's saying that we're going to or if it was just a confirmation of Holler coming back and saying, hey, we went ahead and sent the email for you. To keep it from going into, like, an infinite loop where it just, like, keeps triggering these workflows. It marks it as confirmation, just like kills. It kills the process, basically, at that point. And so this is like the router agent that if we said send it, it'll go ahead and log this information into the Google sheet. Send the email, update the sheet again, tag the email and send that message back to us in Slack saying, yep, we did it. If it is going to determine that. Hey. Tyler said that I needed to adjust this somehow. It's going to send it down to Revision Path, where it's going to log that in Google Sheets. It's going to send this to a sub workflow, which we're going to go look at here in just a second. And then once that's done, it's going to post that new version that comes back from that workflow into Slack. And let us know that it's done that update. And then if it is a confirmation path where, like up here, where CL or hauler comes back and says, hey, we sent that email for you. It makes a note that the confirmation was sent and just stops the workflow. So it doesn't, like, continually loop here. That's how this is working. So if we hit this middle one, though. And it's. It's a revision path. That's where we're going to our. Our last little part of the puzzle right here, which is this revision tool. That is triggered by that other workflow. It, gives it to the Hatch agent. It gives it to the Sugar agent, and it gives it to the Bishop agent, and the library is in here also. So it's essentially just like trying to rerun this, like, expert. Look at this again with Tyler's feedback. Sugar. Try and rewrite it again with Tyler's feedback. Bishop qa. This again. And then send it back to Tyler for review again. So that's what's happening coming out of this one. As well and. That is like what we have now. Originally we had it as the five workflow system, and it can still be run that way. The only difference is this librarian tool like I've mentioned is now we've moved the librarian into the workflow to try and help get some people across the line where they were getting stuck on that from some of the questions in here. So you you could have this set up and working with five workflows. Or you could have it set up and working with four workflows. Depending on if you got blocked or not. And the only one that might be missing is this one right here. This Librarian v2 tool file search is like the one that you might not need. Is what I'm trying to be crystal clear on right here. All right. Sara, where are we at with questions now? Is there anything we need to go back and try and talk?  \
Them: I think it's. It's also about, like, if they have access to that, to the live workflows that you're showing here, showing up on their end, essentially.  \
Me: Yes. Gotcha. Let me find. Where's that other agent we had to build at? It was this one right here. Is it this one? No, it wasn't this one. It was. Here we go. All right, so, yeah. This is the workflow. So just like coming back to where we went to Claude Desktop over here a minute ago and described how do we, like, want this classifier workflow to work? I'm going to go ahead and let's make this publicly accessible.  \
Them: So, you guys, this is not the actual homework. This is like that process that Tyler was showing us before. Like, if you were going to create this from scratch, how would you go about it? Essentially, just wanted to unbundle those. Those things.  \
Me: Copy. Thank you. Yeah. And so. It's finished. So now we can go and look at this. So we took this, this thread that we did in Clog Desktop to describe a thing that we wanted to have built. And we could take that back over into cloud code and do it. But I wanted to show how we could also use the nai or like, there's lots of platforms that have this. Like Cassidy has one, Lindy.com has one. So a lot of these. Excuse me, similar type tools, a lot of them are going to this sort of builder type agent in here that can help with this process, and we've given it that prompt and it's gone ahead and built it out. For us. And then it's telling us what we need to go in and fix here. So it's saying I need to come in and connect my Gmail account. Connect my OpenAI account. And send to the webhook of, like, where's the next workflow that we're going to? Right here, basically? So it did the whole thing. It's built it for us now. So it's just me coming in and assigning the email account that I want to connect it to, like, just literally selecting it from there. Here, it's doing the OpenAI classifier. So I need to set up my credential for OpenAI if that's what I wanted to use. If I did not want to use OpenAI and I wanted to run this differently and make this like running on my open router and use a different model. We could. We could do that, right? Like, we could go back and make this adjustment and have the agent go in and fix that and connect this in with the credential. It's then going to parse it out, categorize it, and then essentially, like, we've recreated a version. Of that first email classifier workflow that we did for for class a year. So you guys can kind of see. How can you very quickly go from idea to any sort of workflow that you want to build? All right. And sara. So help me here just so I'll make sure I'm not missing anything or helping answer questions, too.  \
Them: Yeah. Okay. Can we just go back to the workflows for this? Part two of the homework? Not this one. Like, not the one that was being developed.  \
Me: Gotcha.  \
Them: People want to know exactly how many workflows do I need to be seeing? And which ones are active, inactive? I think there's. There was a question around that. Just so they have a visual of like and a like summarized understanding of what they need to be seeing.  \
Me: Gotcha. Yeah. So for the actual if you're on the week two part of stuff, There could be five workflows that you could use, or there could be four. So for if you want to just take the. The easiest path and not have to worry about this librarian tool right here. Like this is doing effectively the same thing that we we've now just rolled directly in to this, like W1 by bringing the library straight or librarian straight into this. So if all you have is the email classification, that would be step one in the workflow. Or maybe we call it phase one in this process. Phase two is it goes down here to Workflow one, where it's the email processing pipeline. Phase three would be that once it exits from here, it goes into the workflow. Two where it's trying to decide, like, what did we say when we responded back to it in Slack? Pretty much. And then the last thing is this little sub process right here, which is the revision workflow, where if we told it, it needed to be edited, It sends it back down to here. So that's where. Those are the four main workflows. If you're able to get this librarian v tool v2 tool working as it's built right now. You could have five and that would not be wrong. It's just like we swapped one of the parts around, like I'm saying. That that helped get some of these folks unblocked.  \
Them: Okay. And people are saying they don't have an. Like, a few of them aren't there. So I think we just have to show it, like. Like, I mean, do the thing after class and just make sure that everything's pushed out correctly.  \
Me: Okay?  \
Them: Yeah.  \
Me: And. Then. Yeah. Do we have any other questions about stuff as far as, like, still to send week two, or is there anybody talking about, like, echo stuff? I know we hit knowledge based stuff in the stacks earlier. I just want to make sure that we're getting other folks done here.  \
Them: Cool. Yeah, we've got. I think, though, because I was, like, answering questions, so I think you got most of the questions on the stacks thing. Because I think they're older, and you went through, like, the older questions, and you think you went through them. But. But, like, after this class, we'll pull down the Q and A and make sure. Like you'll, you know, if you haven't answered them. Then we'll answer them. And yeah. So. I think we're good. Like, in terms of right now, like, like we said right at the beginning. We'll still. We'll pull down. We'll go and make sure that everything is committed and pushed. Out. We'll have pull down the Q and A form and you guys have the Google sheet to ask questions. And we are going to be processing that, like, through. Through to next week. So even if you're like, oh, I'm behind or whatever, you still have time for us to kind of continue and to support you through the process.  \
Me: To. Support each other.  \
Them: For sure.  \
Me: For. Sure. Yeah, and I. I know too. Like we need to grab and I'll send it to a follow up email to Ileana too for the the video from yesterday from that lightning lesson that even shows this process more in depth on after class. If we're wanting to build some new workflow using this workshop that we've set up now with with Claude and Claude Code and Innate in. How do we go from idea to, like, building something from scratch? Honestly, like, that. That's probably, like, even easier to do that than trying to rebuild some of the stuff that we have in here. Because you. You are the orchestrator at that point. Like, you can control it. You give it all the details. And it's building specifically to your requirements right out of the gate. So that's one thing.  \
Them: And. Oh, sorry. I thought you were done.  \
Me: No, you're good. I was going to say the other thing is like, we, we have still been blocked on being able to do that Loom 2 video. I, I think you all tell me, and I think it's probably going to be like a resounding yes, if it is good for you all as soon as I can get that unblocked, I will just go in, have a fresh pull down from the student repo and walk like beginning to end. How do you set this up? Like, do a complete step by step visual as well for people that learn that way? Because I think that that would just reading through it. And like, chatting with Claude might also be like, a challenging part here, too, for folks.  \
Them: Yeah, there were a lot of moving parts, and we had to, like, go, you know, done rabbit holes and things like that so that we get everyone's questions answered. But we do want to do, like, the big overview.  \
Me: Yeah. You know?  \
Them: And yeah, I think that would be helpful because there are a number of people who, like, I think, have wondered in late and this would be really hard to, like, try to understand. What is happening if you haven't been through the part one, you know, situation as well from last week. So, yeah, so we, we will make sure that we get everything answered for. You guys, I tried my best in the chat and in the Q and A form, but things move fast. You know, but we'll make sure that things also get answered for you in the Google form as they come in. And? And, yeah, like Tyler said, we'll make sure that everything is set up for you and that we support you through the next week or so.  \
Me: Yeah. And, like, just to recap, y'all, because. We try to set the stage, like, at the very beginning. This is a really big mindset shift on how do you even go about building these things? And you're seeing in real time, too, like, even though we have the tools, it still is a bit of a process to, like, go through all of this. Imagine what it's like without the tools to help with this also. And, like, I. I want to just commend you all for sticking with it and going through this and getting this build. It's. It's been awesome seeing more people have been able to use the system. Get through this, and they're actually, like, connecting the dots and learning how to work with Claude code to get these parts and pieces put together. And recognize that, like, this workflow that we're building right here is, like, really extensive. Like, there's. There's multiple different parts and pieces to this system. If Sara and I were building this out for a client. This would easily be. We would be charging them 25k plus just to, like, build and develop and get this in place for them. So just to kind of fix it into your mind of, like, how hard of a workflow are we learning to build to then go and commercialize and get it into production for someone.  \
Them: Yeah, sure. Because I know that there's a few people who are like, I want to do this for my business. And some people are like, I want to do this for clients and stuff like that. And yeah, I, I, I want to, like, echo what Tyler just said. Like, I'm honestly blown away that there's, like, you know, 200 of you here that are just consistently showing up, even though you're finding this challenging. And it's meant. Honestly, it's not meant to be super easy, you know? And you keep showing up and you keep asking the right questions. And you keep letting us know, like, if there's gaps that we need to fill for you. So, like, you guys have such a growth mindset. I shouldn't be surprised because you're in the Mindvalley, like, Mastery Program. But I. But, like, as educators and instructors, we do this like. Like, this is our world, right? And I want to, like, really let you guys know that I'm so impressed with you. Like, I'm so impressed with your just, like, just desire to learn this stuff and to stick with it despite the challenges and despite everything. So. So that. That is, like, I. I want to say, like, that is the hardest part. Like, if you don't have that mindset, this stuff becomes hard. Like, you. You can't go to the next level, but because you guys have that. Mindset, like, you are going to be able to do this because, like, you're already proving it, you know? So don't ever discount yourself or make your, like, feel like, can I do this? Or, you know, am I, like, built for the stuff you can with the right mindset and the commitment and that's? What you guys are demonstrating. For sure.  \
Me: Yeah, that's what it is, because it's really, like, the. The fortitude to just keep at it. And also, like, it's the reps just, like, if any new skill that you're learning.  \
Them: Yeah.  \
Me: This gets easier. Like, we've tried to. Is Vanessa on our team? Says, like, we're trying to put just enough, like, meaningful friction in here. So that, like, you're able to do things even, like coming in and not ever necessarily even working in 8m before, and look how far you've been able to come and where you're going to have what you'll have built coming out of the class. And it gets easier the next time. And you get better with the system as you keep going. Like I can tell you that from our classes. Yeah.  \
Them: Yeah. And. And this is. And this is a 1% skill. Guys, like the stuff that you're learning here is not like, you know, you know, right at the beginning of the chat, GPT journey or whatever. Right? You guys are learning a 1% skill. And so like you, you know, consider yourself in that. In that, like, league, because there aren't many people who can do this stuff. And. And, like, you know, and. And so, like, just to paint the picture about, like, where you guys are at, it is truly the 1% skill.  \
Me: One other quick story is just as we're closing out here, I want to share with you all this, like, it's something that just recently happened, and it's something that we see, like, really often in our, in our own community. But one of our team members. It's in our residence program, which is like a fellowship on our team. He just got into AI on Halloween of last year. We did a live lightning lesson, and my goofy butt wore an inflatable chicken suit from a Halloween outfit to do a. A session that we do over there. And Charlie Fuller's his name. He. He. That's where he first found us. He actually got laid off during that call. On the call, he had to. Like back out of the call.  \
Them: On the call.  \
Me: He went to his HR team and they laid him off. He didn't know that was coming. And then he came back and got on and finished up watching the lightning lesson. It was like, hey, I want to come learn this stuff. And that was. He was starting from step zero, basically from Halloween from last year. He has been doing this stuff for just a little bit over a year now. And he's been on our team for the last six months. He picked this stuff up super quick, by the way. Like, he went through foundations and just was, like, drilling it. And he's really gotten into some more of the advanced stuff here in the last little bit. He just went and applied for a new role because his skill set, he's got. He's. He's been, like, leaps and bounds for it because of the reps. We're like, dude, you need to go out on the open market and see what you can go find because you're, like, super valuable right now. We are so proud to say that he just got and accepted his contract for a brand new job of making multiple six figures. And he's only been doing a. For a year for a massive company that, for the sake of it, I'm not going to say the name, but if. If we did, you would know who they are.  \
Them: Yeah. Global company. Yeah. It's like a multiple, multiple six figure, like salary. And, like, you know, you guys are getting a window into that skill set. And even if you're coming from a business point of view or whatever, like, realize the value of what this can do. Like, if people are willing to pay multiple six figures for someone to come and help, you know, in the whole AI space, their AI, their company. That shows the value of actually understanding what this can do for your business, to take it to the next level. Like Dr. William is saying is like. Like, I don't want to do this. That's totally fine. Not like it's not, you know, you don't. As long as you know, like, what's possible for your business. And the skills that, like, required that. That in and itself is like, you know, it's. It's of value for you to know, so, yeah.  \
Me: Like, the. The other thing, too. Like, one of the reasons, and I guess we can kind of end with this, is one of the reasons that Charlie, not only because he's, like, super, he's an amazing person, and, like, he. His skills match this job well. But from the AI point of view, he did this whole. Thing of what we call show up with a mock up. So when he did his interview, he didn't just submit a resume. He literally showed up with a product that he built bespoke for this company, for this interview, to show them what he could do. Which is exactly the skill set y'all are learning to do here. So when you show up to either a client that you're doing consulting with or. Or development with, or you're trying to go get a job with someone, like being able to. Excuse me. To demonstrate. And even show up with a working mvp. Of something you can quickly spin up for them. Like, they blew his socks off. I mean, he blew their socks off. I should say, with, like, what they built. They're like. You built a product. Are you kidding me? So I just wanted to flag that and give it as just, like, one little story of inspiration here.  \
Them: Yeah.  \
Me: Of like the why behind this, too.  \
Them: Yeah. Because we, like, we expected a. You know, we expect a lot of you with learning this stuff. But, you know, that is, like. We just want to tie it back to why we think this is important for you guys. And, yeah, I really. I'm really excited for you all. You're in a wonderful community. I could see it in the chat, how you guys are supporting each other and, and helping each other out, and you're obviously in a great, like, Mindvalley guys like, great community, great space. A lot of people like that are good people that are wanting to do more in the world. And that's you guys. So, like, it's an honor to be, like, teaching people like you. You go, you guys. When Mindvalley, like, initially reached out to us, like, right. You know, was like. I think it was, like, may or whatever. Last year. It was like I had been a Mindvalley like customer or client and followed them for years. It was just like I am definitely responding to that email that is not going by the or anything like that. But, like, it is just such a we believe, like, the reason that Tyler and I Ileana tell us to shut up if we watch Reviving with everybody. And we the reason we got into the whole education space to begin with is because, like, we are practitioners who do this, work out for companies and do this in real life. And yes, we found that we did enough of these projects to. You know, work out that we had a system that we could teach other people. But, like, the real thing that's driving us. And we had a, like, virtual Christmas party with our community yesterday. Is we want more people like you on the table. Like, we want more people that look like you guys, that come from the same backgrounds that come from our backgrounds. Because, you guys, we are not from AI companies like we were where you were a few years ago. We do not have the background. We did not come from, like, you know, meta AI teams or any of the big AI companies. And those guys come and learn from us now. Like that's the power. And we are so passionate about having more people like us. On the. On the AI table, which has got an infinitely bigger. And we just want to give people the skills. To be able to, like, pull up a seat and sit at the table and, like, make good things happen with this stuff. And I know that that's you guys that we're talking to here, so thank you for. Thank you for the honor of letting us come and teach with you. And like I said, we will. Make sure, like, we continue to support you guys and we'll get the right information pushed out and all of the things. For sure.  \
Me: Yeah. And we can't wait to see, like, what y'all do with us. So, like, please connect with us, you know, afterwards. We'd love to see the success stories and what you've been able to build, and that's always so fun to hear. So we really appreciate you all.  \
Them: Yeah. It is our honor. Sara and Tyler, thank you so much, not just for today, but for all the time and all the care and the generosity you put into supporting the students throughout this series. You have gone way above and beyond to make sure everybody's able to, I think, as you put it, across the finish line with more ease. It's really, truly been such a deep, deep dive. And I really know what you say is so true, that our minds have been stretched and expanded, and we know what's possible when we design systems, and then we know how to do it intentionally from start to finish. And I agree with the students. I love the story you told Tyler because things are moving so fast and it is possible to go from 0 to 100, so to say now in six months.  \
Me: Putting. To support these different. Such. A. Typ. E of. Possible. To. 100.  \
Them: And there is nobody better than you both to take us there. So thank you for that. And your passion really shows. Thank you, guys.  \
Me: Thank you so much. All right.  \
Them: It's been a thank you.  \
Me: Y'all. Well, we're gonna miss you. We'll. We'll be talking to you, I guess, like a little bit through the forms and things. So continue to use those and reach out, connect with us. We're on LinkedIn and all the social medias you can find us on there. Yeah, we really appreciate it and wish you all a happy holiday season and happy building.  \
Them: Thank you so much, guys. Bye. Have a wonderful weekend. }